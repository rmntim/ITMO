{"cells":[{"cell_type":"markdown","id":"1e9cded8","metadata":{"id":"1e9cded8"},"source":["# ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ·Ğ°Ğ½ÑÑ‚Ğ¸Ğµ 14: Ğ£Ğ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ† Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ°"]},{"cell_type":"markdown","id":"8f494ae0","metadata":{"id":"8f494ae0"},"source":["**Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ²ÑĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ ÑÑ€ĞµĞ´ÑÑ‚Ğ²Ğ°, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑƒÑĞºĞ¾Ñ€Ğ¸Ñ‚ÑŒ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†** (AI, Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸, Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¸, Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€ĞºĞ¸, Ğ²ÑÑ‘ Ñ‡Ñ‚Ğ¾ ÑƒĞ³Ğ¾Ğ´Ğ½Ğ¾).\n","\n","Ğ’Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ´ Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸, ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Python ĞºĞ¾Ğ´, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº CUDA, Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ‚Ğ¾Ñ€Ñ‹, Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ C/C++), Ğ²ÑÑ‘ Ñ‡Ñ‚Ğ¾ ÑƒĞ³Ğ¾Ğ´Ğ½Ğ¾. ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ² ÑÑ‚Ğ¾Ñ‚ Ğ½Ğ¾ÑƒÑ‚Ğ±ÑƒĞº (Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ AI). Ğ•ÑĞ»Ğ¸ Ñ€ĞµÑˆĞ¸Ğ»Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ ÑĞ·Ñ‹Ğº Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ ÑĞ´Ñ€Ğ¾ (Jupyter kernel) Ğ½Ğ¾ÑƒÑ‚Ğ±ÑƒĞºĞ°, ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¸Ñ… Ğ² Ğ²Ğ¸Ğ´Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ¿Ğ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°.\n","\n","ĞŸÑ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞ¹Ñ‚Ğµ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ `send_results`.\n","\n","*ĞŸĞ¾Ğ¼Ğ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ AI Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¸ Ğ² Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğ¸ ĞºĞ¾Ğ´Ğ°, Ğ½Ğ¾ Ğ²Ğ¾Ñ‚ Ñ Ñ‚ĞµĞ¾Ñ€Ğ¸ĞµĞ¹ Ñ€Ğ°Ğ·Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒÑÑ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³ÑƒÑ‚.*\n","\n","Ğ Ğ°Ğ·ÑƒĞ¼ĞµĞµÑ‚ÑÑ, Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ, Ñ‡Ñ‚Ğ¾ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¾, Ğ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ learn by practice Ğ½Ğ¸ĞºÑ‚Ğ¾ Ğ½Ğµ Ğ¾Ñ‚Ğ¼ĞµĞ½ÑĞ»: Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¸Ğ³Ñ€Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ¿Ğ¸Ğ°Ğ½Ğ¸Ğ½Ğ¾, Ğ¸Ğ·ÑƒÑ‡Ğ°Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ¾Ñ‚Ñ‹, Ğ½ĞµĞ»ÑŒĞ·Ñ Ñ€Ğ°Ğ·Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒÑÑ Ğ² Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ, Ğ·Ğ°ÑƒÑ‡Ğ¸Ğ²Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ñ‹, Ğ½Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ Ğ¸Ñ… Ğ½Ğ° Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞµ, Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ´, Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ±ÑƒÑ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¾ Ñ€ÑƒĞºĞ°Ğ¼Ğ¸. ğŸ¥°Ğ’Ñ‹ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ Ğ²ÑĞµĞ¼ ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ĞµÑÑŒ, Ğ½Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ¼ĞµĞ»ĞµĞµ!"]},{"cell_type":"code","execution_count":1,"id":"5a3bf905","metadata":{"id":"5a3bf905","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747154231082,"user_tz":-180,"elapsed":3267,"user":{"displayName":"Ğ Ğ¾Ğ¼Ğ°Ğ½ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞºĞ¸Ğ½","userId":"08933816501814017249"}},"outputId":"489a42cf-bdb0-4404-d21c-6e3b123400d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n","Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n"]}],"source":["!pip install gspread"]},{"cell_type":"code","execution_count":2,"id":"bd0cf559","metadata":{"id":"bd0cf559","executionInfo":{"status":"ok","timestamp":1747154241845,"user_tz":-180,"elapsed":10766,"user":{"displayName":"Ğ Ğ¾Ğ¼Ğ°Ğ½ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞºĞ¸Ğ½","userId":"08933816501814017249"}}},"outputs":[],"source":["import datetime\n","import gspread\n","from google.auth import default\n","from google.colab import auth\n","\n","auth.authenticate_user()\n","creds, _ = default()\n","\n","gc = gspread.authorize(creds)\n","\n","# ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, ÑƒĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ ÑĞ²Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ½Ğ¾Ğ¼ĞµÑ€ Ğ˜Ğ¡Ğ£.\n","# Ğ’Ğ½Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ’Ğ°Ğ¼Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹, Ğ²Ğ°Ğ¶ĞµĞ½ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ, Ğ½Ğ° Ğ±Ğ°Ğ»Ğ»Ğ°Ñ… Ğ·Ğ° Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºÑƒ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° Ğ½Ğµ ÑĞºĞ°Ğ¶ÑƒÑ‚ÑÑ, Ğ½Ğ¾ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ° - ÑĞºĞ°Ğ¶ĞµÑ‚ÑÑ.\n","# ĞĞµ Ğ±Ğ¾Ğ¹Ñ‚ĞµÑÑŒ Ñ‡Ğ°Ñ‰Ğµ Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ¾Ğ¼, Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼, Ñ‡ĞµĞ³Ğ¾ Ğ¼Ñ‹ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ´Ğ¾Ğ±Ğ¸Ñ‚ÑŒÑÑ Ğ²ÑĞµ Ğ²Ğ¼ĞµÑÑ‚Ğµ!\n","my_isu_id = \"409682\"\n","\n","spreadsheet = gc.open_by_key('1D60V_sOW3SvMiquZXmM2zFAqQq_ViAbRdmu_nNNNqKg')\n","# Ğ•ÑĞ»Ğ¸ Ğ’Ñ‹ Ñ€ĞµÑˆĞ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ¹Ñ‚Ğ¸ Ğ´Ğ°Ğ»ÑŒÑˆĞµ Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ñƒ Ğ’Ğ°Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¸ Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¼ Ğ¯ĞŸ, Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ¼Ğ½Ğµ, Ñ Ğ¿Ñ€Ğ¸ÑˆĞ»Ñ Ğ’Ğ°Ğ¼ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ ÑÑÑ‹Ğ»ĞºÑƒ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²\n","worksheet = spreadsheet.get_worksheet(0)\n","\n","\n","def send_results(computation_time, comment):\n","    if my_isu_id == \"CHANGE_ME\": # Ğ”Ğ°, Ğ²Ğ¾Ñ‚ Ñ‚Ğ°ĞºĞ°Ñ Ğ¿Ñ€Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°, ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ Ğ’Ñ‹ Ñ€Ğ°Ğ·ÑƒĞ¼ĞµĞµÑ‚ÑÑ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¾Ğ±Ğ¾Ğ¹Ñ‚Ğ¸, Ğ½Ğ¾ Ğ·Ğ°Ñ‡ĞµĞ¼? Ğ¢Ğ°Ğº Ğ²ĞµĞ´ÑŒ Ğ½Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾!\n","        print(\"Please set your ISU ID in the script.\")\n","    else:\n","        # Ğ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ Ğ²Ğ¾Ğ²ÑĞµ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑ, Ğ²ÑÑ‘ Ğ’Ğ°Ğ¼ Ğ½Ğ° Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ğ¸.\n","        # Ğ’ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñ‹ Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ¼ÑÑ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ n=1000\n","        # Ğ¡ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ , Ğ¿Ğ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ’Ñ‹ Ğ´ĞµĞ»Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞµĞ³Ğ¾, ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ Ğ¸ Ğ’Ğ°Ğ¼ Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ»Ğ¾Ğ³Ğ°.\n","        submission_data = [my_isu_id, computation_time, comment, datetime.datetime.now(datetime.timezone.utc).isoformat()]\n","        worksheet.append_row(submission_data)"]},{"cell_type":"markdown","source":["ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²:"],"metadata":{"id":"0OPdgy5S9ejG"},"id":"0OPdgy5S9ejG"},{"cell_type":"code","source":["import time\n","\n","a = time.time()\n","time.sleep(10)\n","b = time.time()\n","\n","computation_time = b - a\n","send_results(computation_time, \"test\")"],"metadata":{"id":"3uvWVTqz7Ouk","executionInfo":{"status":"ok","timestamp":1747154253663,"user_tz":-180,"elapsed":11816,"user":{"displayName":"Ğ Ğ¾Ğ¼Ğ°Ğ½ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞºĞ¸Ğ½","userId":"08933816501814017249"}}},"id":"3uvWVTqz7Ouk","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Ğ¡Ñ‚Ğ°Ñ‚ÑŒĞ¸:\n","- [Matrix Multiplication: 2020 Update](https://martin-thoma.com/matrix-multiplication-2020/)\n","- [Discovering faster matrix multiplication algorithms with reinforcement learning](https://www.nature.com/articles/s41586-022-05172-4#data-availability)\n","- [Ğ£ÑĞºĞ¾Ñ€ÑĞµĞ¼ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² 170 000 Ñ€Ğ°Ğ· Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Python](https://habr.com/ru/companies/ncloudtech/articles/790370/)\n","- [ĞšĞ½Ğ¸Ğ³Ğ°: High Performance Python](https://disk.yandex.ru/i/GNbAQkPgbK07VQ)\n","- [ĞšĞ½Ğ¸Ğ³Ğ°: Introduction to High Performance Computing for Scientists](https://disk.yandex.ru/i/H6pFi9ydA2pbbg)\n","- [ĞšĞ½Ğ¸Ğ³Ğ°: Scientific Computing with Python High-performance scientific computing with NumPy, SciPy, and pandas](https://disk.yandex.ru/i/xaBdcbN5yx9gaA)\n","- [ĞšĞ½Ğ¸Ğ³Ğ°: Matrix computations](https://disk.yandex.ru/i/RfL8Ca9Q0341vA)\n","- [Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 2021: Selecting Algorithms for Black Box Matrices: Checking for\n","Matrix Properties That Can Simplify Computations](https://disk.yandex.ru/i/oTMSLOJd1xZBXQ)\n","- [CÑ‚Ğ°Ñ‚ÑŒÑ 2024 Ğ¾Ñ‚ Alman Ğ¸ Williams: A refined Laser Method and Faster Matrix Muliplication](https://disk.yandex.ru/i/bNxAS2M3-OoM_Q)\n","- [Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ: Anatomy of High-Performance Matrix Multiplication](https://disk.yandex.ru/i/bBnyORYiXFwsFw)\n","- [Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 1997: Implementation of Strassen's Algorithm for Matrix Multiplication](https://disk.yandex.ru/i/nvlvKJciVuOwmw)\n","- [Numerical algorithms for high-performance computational science](https://disk.yandex.ru/i/9nhTq2ZbSjyCxw)\n","- [Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Nature 2021: Discovering faster matrix multiplication\n","algorithms with reinforcement learning](https://disk.yandex.ru/i/Lu6A9BNzlV-wWg)\n","- [ĞšĞ½Ğ¸Ğ³Ğ°: Optimisation of a modern numerical library: a bottom-up approach](https://disk.yandex.ru/i/czZCCiV7TLf68w)\n","- [ĞšĞ½Ğ¸Ğ³Ğ°: A Primer on Scientific Programming with Python](https://disk.yandex.ru/i/2409GOx6pcLS_w)\n","- [Ğ¡Ğ»Ğ°Ğ¹Ğ´Ñ‹: High-performance Matrix Computations](https://disk.yandex.ru/i/XqOAFw-nDskoEw)\n","- [Ğ¡Ğ»Ğ°Ğ¹Ğ´Ñ‹: Strassenâ€™s Algorithm for Matrix Multiplication, QuickSelect, and Median of Medians](https://disk.yandex.ru/i/cJB-2JCqr216Tg)\n","- [Ğ¡Ğ»Ğ°Ğ¹Ğ´Ñ‹: Communication-Avoiding Algorithms for Linear Algebra, Machine Learning and Beyond](https://disk.yandex.ru/i/xuaa9LITj6SKUw) + [Ğ²Ğ¸Ğ´ĞµĞ¾](https://www.youtube.com/watch?v=JwCWPteaih4)"],"metadata":{"id":"mpSzXCTTGwe5"},"id":"mpSzXCTTGwe5"},{"cell_type":"markdown","id":"fb101e5f","metadata":{"id":"fb101e5f"},"source":["\n","\n","\n","### Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ (Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¸):\n","*Ñ€Ğ°Ğ·ÑƒĞ¼ĞµĞµÑ‚ÑÑ, Ğ½ĞµÑ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ñ… Ğ²ÑĞµ, Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ğ¹Ñ‚Ğµ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ’Ğ°ÑˆĞµĞ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸*\n","- [line profiler](https://kernprof.readthedocs.io/en/latest/) : line-by-line profiling of functions\n","- [Scalene](https://github.com/plasma-umass/scalene) : A CPU+GPU+memory sampling based profiler.\n","- [PyInstrument](https://github.com/joerick/pyinstrument) : A call stack profiler\n","- [Yappi](https://github.com/sumerc/yappi) : A tracing profiler that is multithreading, asyncio and gevent aware.\n","- [profile / cProfile](https://docs.python.org/3/library/profile.html) : The builtin profile module.\n","- [SnakeViz](https://jiffyclub.github.io/snakeviz/) : vizualise of cProfile output.\n","- [timeit](https://docs.python.org/3/library/timeit.html) : The builtin timeit module for profiling single statements\n","- [timerit](https://github.com/Erotemic/timerit) : A multi-statements alternative to the builtin timeit module.\n","- [torch.profiler](https://docs.pytorch.org/docs/stable/profiler.html) : tools for profiling torch code\n","\n","### Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ‚Ğ¾Ñ€Ñ‹\n","- [Python 3.11.3](https://www.python.org/downloads/release/python-3113/)\n","- [PyPy](https://pypy.org/)\n","- [Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ Ñ‚Ñ€Ğ°ÑĞ»ÑÑ‚Ğ¾Ñ€Ñ‹ Ğ¸ Ğ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¸](https://pybenchmarks.org/)\n","- [Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ´ĞµÑ€ Ğ´Ğ»Ñ Jupyter Notebook Ğ¿Ğ¾Ğ´ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¯ĞŸ](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels)"]},{"cell_type":"markdown","source":["ĞĞ°Ğ¸Ğ²Ğ½Ğ°Ñ ijk Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°"],"metadata":{"id":"9UE6JWSy-O96"},"id":"9UE6JWSy-O96"},{"cell_type":"code","execution_count":4,"id":"7faa30e2","metadata":{"id":"7faa30e2","executionInfo":{"status":"ok","timestamp":1747154255359,"user_tz":-180,"elapsed":1693,"user":{"displayName":"Ğ Ğ¾Ğ¼Ğ°Ğ½ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞºĞ¸Ğ½","userId":"08933816501814017249"}}},"outputs":[],"source":["import numpy as np\n","import time\n","\n","n = 10000\n","x = np.random.randn(n,n)\n","\n","def matrix_mult(A, B):\n","    \"\"\"Multiplies two matrices A and B.\"\"\"\n","    if len(A[0]) != len(B):\n","        raise ValueError(\"Number of columns in A must be equal to number of rows in B\")\n","\n","    result = []\n","    for i in range(len(A)):\n","        row = []\n","        for j in range(len(B[0])):\n","            sum = 0\n","            for k in range(len(B)):\n","                sum += A[i][k] * B[k][j]\n","            row.append(sum)\n","        result.append(row)\n","    return result"]},{"cell_type":"markdown","source":["Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸, Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ñ‡ĞµĞµ."],"metadata":{"id":"jXceWK8_0LYj"},"id":"jXceWK8_0LYj"},{"cell_type":"code","source":["!pip install torch numpy yappi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvOiDsLpdTok","executionInfo":{"status":"ok","timestamp":1747154341314,"user_tz":-180,"elapsed":85959,"user":{"displayName":"Ğ Ğ¾Ğ¼Ğ°Ğ½ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞºĞ¸Ğ½","userId":"08933816501814017249"}},"outputId":"25b7850f-11e2-4ce4-adc3-4970dc4d5c02"},"id":"ZvOiDsLpdTok","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Collecting yappi\n","  Downloading yappi-1.6.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yappi-1.6.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: yappi, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 yappi-1.6.10\n"]}]},{"cell_type":"markdown","source":["### ğŸ”„ **Low-Precision / Quantized MatMul**\n","\n","#### ğŸ“Œ What:\n","\n","* Reduce precision to FP16, INT8, or even binary for speedup.\n","\n","#### ğŸ’¡ Optimization Focus:\n","\n","* Saturating arithmetic\n","* Vectorized packing/unpacking\n","* Quantization-aware fusion (scaling factors, zero-points)\n","\n","#### ğŸ§ª Try This:\n","\n","* Use **TensorRT**, **ONNX Runtime**, or **custom C++/Python code**"],"metadata":{"id":"V80BYnHZ12RV"},"id":"V80BYnHZ12RV"},{"cell_type":"markdown","source":["Low-Precision Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚, ĞºĞ¾Ğ³Ğ´Ğ° ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ğ°Ğ¶Ğ½ĞµĞµ Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ¡Ğ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ±Ğ¸Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ (8/16 Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 32/64) ÑƒÑĞºĞ¾Ñ€ÑĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ¾Ğ² (Tensor Cores Ğ´Ğ»Ñ FP16), ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‚ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ (FP16 Ğ² 2x ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½ĞµĞµ FP32) Ğ¸ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ ÑĞ½ĞµÑ€Ğ³Ğ¾Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ, Ñ‡Ñ‚Ğ¾ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ² Ğ¸ Ğ´Ğ°Ñ‚Ğ°-Ñ†ĞµĞ½Ñ‚Ñ€Ğ¾Ğ². ĞĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ 95-99% Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ°Ğ¶Ğµ Ñ INT8, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ²Ñ€Ğ¾Ğ´Ğµ CV Ğ¸Ğ»Ğ¸ NLP. ĞĞ´Ğ½Ğ°ĞºĞ¾ Ğ½Ğ¸Ğ·ĞºĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ´Ğ»Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑ‡ĞµÑ‚Ğ¾Ğ² Ğ¸Ğ»Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ², Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğº Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼, Ğ³Ğ´Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ. Ğ­Ñ‚Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ° Ğ½Ğµ Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹."],"metadata":{"id":"XErvATt_gmu6"},"id":"XErvATt_gmu6"},{"cell_type":"code","source":["import yappi\n","import torch\n","import numpy as np\n","import time\n","from math import log2, ceil\n","\n","MATRIX_SIZE = 4096\n","NUM_RUNS = 100\n","\n","def setup_matrices(dtype, device='cuda'):\n","    \"\"\"Create test matrices with specified precision\"\"\"\n","    a = torch.randn(MATRIX_SIZE, MATRIX_SIZE, device=device)\n","    b = torch.randn(MATRIX_SIZE, MATRIX_SIZE, device=device)\n","    return a.to(dtype), b.to(dtype)\n","\n","def quantize_fp8(tensor, exp_bits=4, man_bits=3):\n","    \"\"\"Simulate FP8 quantization (E4M3 format)\"\"\"\n","    max_exp = 2**(exp_bits - 1) - 1\n","    scale = (2**max_exp) / tensor.abs().max().clamp(min=1e-8)\n","\n","    scaled = tensor * scale\n","    exp = torch.floor(torch.log2(scaled.abs().clamp(min=2**-max_exp)))\n","    man = torch.round(scaled / (2**exp) * (2**man_bits)) / (2**man_bits)\n","    quantized = torch.sign(scaled) * man * (2**exp)\n","\n","    return quantized / scale\n","\n","def fp8_matmul():\n","    \"\"\"Simulated FP8 matrix multiplication\"\"\"\n","    a, b = setup_matrices(torch.float32)\n","    a_quant = quantize_fp8(a)\n","    b_quant = quantize_fp8(b)\n","    return torch.matmul(a_quant, b_quant)\n","\n","def quantize_fp4(tensor, exp_bits=2, man_bits=1):\n","    \"\"\"Simulate FP4 quantization (E2M1 format)\"\"\"\n","    max_exp = 2**(exp_bits - 1) - 1\n","    scale = (2**max_exp) / tensor.abs().max().clamp(min=1e-8)\n","\n","    scaled = tensor * scale\n","    exp = torch.floor(torch.log2(scaled.abs().clamp(min=2**-max_exp)))\n","    man = torch.round(scaled / (2**exp) * (2**man_bits)) / (2**man_bits)\n","    quantized = torch.sign(scaled) * man * (2**exp)\n","\n","    return quantized / scale\n","\n","def fp4_matmul():\n","    \"\"\"Simulated FP4 matrix multiplication\"\"\"\n","    a, b = setup_matrices(torch.float32)\n","    a_quant = quantize_fp4(a)\n","    b_quant = quantize_fp4(b)\n","    return torch.matmul(a_quant, b_quant)\n","\n","def fp16_matmul():\n","    \"\"\"FP16 matrix multiplication using Tensor Cores\"\"\"\n","    a, b = setup_matrices(torch.float16)\n","    return torch.matmul(a, b)\n","\n","def int8_matmul():\n","    \"\"\"INT8 quantized matrix multiplication\"\"\"\n","    a, b = setup_matrices(torch.float32, device='cpu')\n","    scale = 127.0 / max(a.abs().max(), b.abs().max())\n","    a_quant = torch.quantize_per_tensor(a, scale, 0, torch.qint8)\n","    b_quant = torch.quantize_per_tensor(b, scale, 0, torch.qint8)\n","    return torch.ops.quantized.matmul(a_quant, b_quant, scale, 0).dequantize()\n","\n","def binary_matmul():\n","    \"\"\"Binary matrix multiplication simulation\"\"\"\n","    a = torch.sign(torch.randn(MATRIX_SIZE, MATRIX_SIZE))\n","    b = torch.sign(torch.randn(MATRIX_SIZE, MATRIX_SIZE))\n","    return a @ b\n","\n","def profile_operation(op_fn, op_name):\n","    \"\"\"Profile a matrix multiplication operation\"\"\"\n","    # Warmup\n","    for _ in range(3):\n","        _ = op_fn()\n","\n","    # Profile\n","    yappi.start()\n","    start_time = time.time()\n","    for _ in range(NUM_RUNS):\n","        _ = op_fn()\n","    total_time = time.time() - start_time\n","    yappi.stop()\n","\n","    # Get detailed statistics\n","    stats = yappi.get_func_stats()\n","    matmul_time = sum(s.ttot for s in stats if 'matmul' in s.name)\n","    setup_time = sum(s.ttot for s in stats if 'setup_matrices' in s.name)\n","\n","    send_results(total_time/NUM_RUNS, f\"{op_name}: Total time/run\")\n","    send_results(matmul_time/NUM_RUNS, f\"{op_name}: Pure matmul time\")\n","    send_results(setup_time/NUM_RUNS, f\"{op_name}: Setup time\")\n","\n","    # Memory analysis\n","    mem_stats = yappi.get_mem_usage()\n","    send_results(mem_stats/1024**2, f\"{op_name}: Peak memory (MB)\")\n","\n","    yappi.clear_stats()\n","\n","def main():\n","    if not torch.cuda.is_available():\n","        print(\"CUDA not available - some operations will be CPU-bound\")\n","\n","    yappi.set_clock_type(\"cpu\")\n","\n","    print(\"Profiling FP16...\")\n","    profile_operation(fp16_matmul, \"FP16\")\n","\n","    print(\"\\nProfiling FP8...\")\n","    profile_operation(fp8_matmul, \"FP8\")\n","\n","    print(\"\\nProfiling FP4...\")\n","    profile_operation(fp4_matmul, \"FP4\")\n","\n","    print(\"\\nProfiling INT8...\")\n","    profile_operation(int8_matmul, \"INT8\")\n","\n","    print(\"\\nProfiling Binary...\")\n","    profile_operation(binary_matmul, \"Binary\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2JzRK796gDtL","executionInfo":{"status":"ok","timestamp":1747155106303,"user_tz":-180,"elapsed":336776,"user":{"displayName":"Ğ Ğ¾Ğ¼Ğ°Ğ½ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞºĞ¸Ğ½","userId":"08933816501814017249"}},"outputId":"e6cf0dcd-10b9-4ef5-ccbf-7d2a3475e70e"},"id":"2JzRK796gDtL","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Profiling FP16...\n","\n","Profiling FP8...\n","\n","Profiling FP4...\n","\n","Profiling INT8...\n","\n","Profiling Binary...\n"]}]},{"cell_type":"markdown","source":["# Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ\n","\n","Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ, ĞºĞ°ĞºĞ¾Ğ¹ Ğ¾Ğ¿Ñ‹Ñ‚ Ğ’Ñ‹ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ Ğ´Ğ»Ñ ÑĞµĞ±Ñ? ĞšĞ°Ğº Ğ’Ñ‹ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚Ğµ ÑĞ²Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ? ĞšĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ±Ñ‹ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ ÑĞµĞ³Ğ¾Ğ´Ğ½ÑÑˆĞ½ĞµĞµ Ğ·Ğ°Ğ½ÑÑ‚Ğ¸Ğµ Ğ¿Ğ¾ Ğ’Ğ°ÑˆĞµĞ¼Ñƒ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ?\n","\n","ĞŸĞ¾Ğ½ÑĞ», ĞºĞ°Ğº ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ (FP16/INT8) ÑƒÑĞºĞ¾Ñ€ÑĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‚ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ. ĞĞ° Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞµ ÑƒĞ²Ğ¸Ğ´ĞµĞ» Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ñƒ Ğ² ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ FP32 Ğ¸ FP16. ĞĞ°ÑƒÑ‡Ğ¸Ğ»ÑÑ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¼Ñƒ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² PyTorch, Ğ½Ğ¾ Ğ¿ÑƒÑ‚Ğ°ÑÑÑŒ Ğ² Ğ¿Ğ¾Ğ´Ğ±Ğ¾Ñ€Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² (scale, zero_point).\n","**Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ:**\n","- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸/Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ½Ğ°Ğ³Ğ»ÑĞ´Ğ½Ğ¾ÑÑ‚Ğ¸.\n","- ĞœĞ¸Ğ½Ğ¸-ÑĞ¾Ñ€ĞµĞ²Ğ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ´Ğ°.\n","- ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ· Ğ¶Ğ¸Ğ·Ğ½Ğ¸ (Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ, Raspberry Pi).\n","\n","ĞšĞ¾Ñ€Ğ¾Ñ‡Ğµ: Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾, Ğ½Ğ¾ Ñ…Ğ¾Ñ‚ĞµĞ»Ğ¾ÑÑŒ Ğ±Ñ‹ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞµĞ¹ÑĞ¾Ğ² Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¾Ğ² ğŸš€."],"metadata":{"id":"rYkqCaN_X4TC"},"id":"rYkqCaN_X4TC"}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}