{"cells":[{"cell_type":"markdown","id":"ab461380","metadata":{"id":"ab461380"},"source":["# Практическая работа 12: Исследование работы LLM в контексте работы с собственными числами матрицы"]},{"cell_type":"markdown","id":"c4218c1a","metadata":{"id":"c4218c1a"},"source":["Ваше ФИО:\n","\n","Тимошкин Роман Вячеславович"]},{"cell_type":"markdown","id":"f9cde448","metadata":{"id":"f9cde448"},"source":["Что хотим сегодня изучить:\n","1. Реализации методов поиска собственных значений и собственных векторов на Python\n","2. Метод главных компонент, который много где используется сам по себе и основан на работе с собственными значениями матриц\n","3. Метод главных компонент для оптимизации (уменьшения размеров) модели LLM\n","4. Общение с AI-ассистентами (готовыми LLM) для исследования (изучения) новой предметной области (пункт 3 из списка ниже)\n","5. Научиться писать промпты к LLM так, чтобы получать адекватные и неадекватные результаты (галлюцинации)\n","6. Находить и устранять галлюцинации LLM в программировании и исследовании, когда предметная область Вам уже знакома (пункт 2 из списка ниже)\n","7. Научиться оптимизировать модели LLM и проверять их точность (пункт 1 из списка ниже)"]},{"cell_type":"markdown","id":"4d3f4964","metadata":{"id":"4d3f4964"},"source":["В контексте использования large language model (LLM) термин \"исследование\" обычно относится к процессу изучения, разработки или применения LLM для достижения научных, технических или академических целей. Он может иметь несколько значений в зависимости от конкретного контекста:\n","\n","1. **Разработка модели**: Исследование включает в себя создание или совершенствование LLM, включая проектирование архитектуры, оптимизацию алгоритмов обучения или повышение производительности (например, точности, результативности или обобщения). Этим часто занимаются исследователи ИИ или инженеры.\n","\n","2. **Изучение возможностей**: Исследование может означать изучение того, что могут делать LLM, например, тестирование их способности решать конкретные задачи (например, понимать естественный язык, рассуждать или генерировать код) или оценку их ограничений и предубеждений.\n","\n","3. **Применение к предметной области**: Использование LLMS для поддержки исследований в других областях, таких как анализ научной литературы, генерация гипотез или автоматизация обработки данных в таких дисциплинах, как медицина, физика или социальные науки.\n","\n","4. **Влияние на этику и общество**: Изучение последствий внедрения LLM, включая справедливость, безопасность, риски дезинформации или экологические издержки, связанные с обучением и выводами.\n","\n","Например, исследователь может использовать LLM для анализа обширных наборов данных для исследования (прикладной работы) или для экспериментов с тонкой настройкой, чтобы улучшить производительность при выполнении узкоспециализированной задачи (разработка). Термин является широким, но обычно подразумевает систематическое изучение или экспериментирование с участием LLM."]},{"cell_type":"markdown","id":"3edbe6b7","metadata":{"id":"3edbe6b7"},"source":["### **План работы (разделы ноутбука)**\n","1. Выбрать один или несколько AI-ассистентов из списка ниже и перечислить их ниже.\n","2. Написать промпт (желательно один, чтобы можно было корректнее сравнить результат) на любой языке, на котором Вы ожидаете получить лучший результат, в результате которого выбрать модель с весами LLM для скачивания. Далее будем работать с этой моделью как с матрицей. Сравните ответы полученные от разных LLM в таблице.\n","3. После этого с помощью того же или нового набора AI-ассистентов, получите сниппет для скачивания и начала работы с моделью. Вставьте сниппеты в соответствующие ячейки. Запустите ячейки и сравните полученные результаты, не внося дополнительных изменений в код, если он не работает.\n","4. Если код после запуска не работает, получите у соответствующего AI-ассистента рекомендации по исправлению кода. Вставьте исправленный код в новую соответствующую ячейку. Запустите код и в случае, если код снова не работает, получите новые исправления. Продолжайте либо, пока код не заработает, либо пока AI-ассистент не начнёт слишком сильно галлюцинировать. Протоколируйте все диалоги в соответствующие ячейки. Проведите анализ полученных результатов в текущем разделе.\n","5. Напишите собственные реализации методов нахождения собственных чисел и собственных векторов матриц, используя вызовы готовых реализаций в стандартных библиотеках или подробные описания.\n","6. Заставьте AI-агентов написать сниппеты для тех же методов. Сравните на любой матрце.\n","7. Исследуйте метод главных компонент для оптимизации размера выбранной модели при помощи собственных значений и собственных векторов. Сравните результаты работы модели до и после оптимизации.\n","8. Заключение."]},{"cell_type":"markdown","id":"49d76d05","metadata":{"id":"49d76d05"},"source":["---"]},{"cell_type":"markdown","id":"50db8ee5","metadata":{"id":"50db8ee5"},"source":["## Раздел 1. Выбрать один или несколько AI-ассистентов из списка ниже и перечислить их ниже."]},{"cell_type":"markdown","id":"b204eb72","metadata":{"id":"b204eb72"},"source":["Список:\n","\n","- [ChatGPT (OpenAI)](https://chatgpt.com/)\n","- [Claude (Anthropic)](https://claude.online/chat)\n","- [Gemini (Google)](https://gemini.google.com/app)\n","- [Grok (xAI)](https://grok.com/)\n","- [Perplexity](https://www.perplexity.ai/)\n","- [DeepSeek](https://chat.deepseek.com/)\n","- [Qwen](https://chat.qwen.ai/)\n","- [Llama (Meta AI)](https://huggingface.co/chat/) c учетной записью от Hugging Face\n","- [Mistral](https://mistral.ai/)\n","- [OpenAssistant](https://open-assistant.io/chat/)\n","- [GigaChat (Sber)](https://giga.chat/#chat)\n","\n","- [Microsoft Copilot](https://copilot.microsoft.com/chats/)\n","- [Tabnine](https://www.tabnine.com/pricing/) - платно, но есть триал\n","- [Amazon Q Developer](https://aws.amazon.com/ru/q/developer/)\n","- [GitHub Copilot](https://github.com/copilot)\n","\n","Вы также можете использовать модели, которые не попали в список, но обязательно указывайте их источник, название и прочие аттрибуты."]},{"cell_type":"markdown","id":"a1c6e50e","metadata":{"id":"a1c6e50e"},"source":["---"]},{"cell_type":"markdown","id":"d0b97a90","metadata":{"id":"d0b97a90"},"source":["## Раздел 2. Написать промпт, отправить AI-ассистентам, сравнить результаты\n","2.1. Написать промпт (желательно один, чтобы можно было корректнее сравнить результат) на любой языке, на котором Вы ожидаете получить лучший результат, в результате которого **выбрать** модель с весами LLM для скачивания (желательно выбирать небольшие модели, чтобы скачивать было не много и матрицы были не слишком большими). Далее будем работать с этой моделью как с матрицей.\n","\n","2.2. Отправить промпт AI-ассистентам, выбранным в разделе 1.\n","\n","2.3. Сравните ответы полученные от разных LLM в таблице.\n","\n","2.4. Выбрать модель для скачивания"]},{"cell_type":"markdown","id":"58a51121","metadata":{"id":"58a51121"},"source":["### 2.1 Использованный промпт:\n","\n","Посоветуй, пожалуйста, несколько небольших по размеру (до 1 миллиарда параметров) предобученных моделей LLM (трансформеров), которые можно легко скачать с Hugging Face. Укажи их названия (идентификаторы на Hugging Face) и краткое описание или область применения. Мне нужна модель для экспериментов с матрицами весов."]},{"cell_type":"markdown","id":"944e8ddc","metadata":{"id":"944e8ddc"},"source":["### 2.3. Сравнение результатов\n","\n","| **Ассистент** | **Ответ** |**Ваш комментарий**|\n","|---|---|---|\n","|Gemini (Google)| Предложил `TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T`, `EleutherAI/pythia-410m`, `distilbert/distilgpt2`. Дал краткие описания и идентификаторы HF. | Ответ релевантный, модели подходят по размеру. |\n","|ChatGPT (OpenAI)| Предложил `tiiuae/falcon-rw-1b`, `EleutherAI/gpt-neo-1.3B`, `facebook/opt-1.3b`. Предоставил описания и идентификаторы HF. | Ответ также хороший, предложил разнообразные варианты. |\n","|DeepSeek| Предложил `openai-community/gpt2`, `distilbert/distilgpt2`, `huawei-noah/TinyBERT_General_4L_312D`. Дал описания и ссылки на HF. | Дал самые легкие модели, указал идентификаторы для скачивания. |"]},{"cell_type":"markdown","id":"65dbdf48","metadata":{"id":"65dbdf48"},"source":["### 2.4. Выбранная модель\n","\n","Для дальнейшей работы выбрана модель `distilbert/distilgpt2`, так как она является стандартной небольшой моделью, предложенной всеми ассистентами, и хорошо подходит для экспериментов из-за своего относительно небольшого размера и известной архитектуры."]},{"cell_type":"markdown","id":"ec640cab","metadata":{"id":"ec640cab"},"source":["---"]},{"cell_type":"markdown","id":"9dfe2f28","metadata":{"id":"9dfe2f28"},"source":["## Раздел 3. Скачивание модели с помощью сниппетов от AI-ассистентов\n","С помощью того же или нового набора AI-ассистентов, получите сниппет для скачивания и начала работы с моделью. Вставьте сниппеты в соответствующие ячейки. Запустите ячейки и сравните полученные результаты, не внося дополнительных изменений в код, если он не работает.\n","\n","3.1. Список используемых AI\n","\n","3.2. Сниппеты для скачивания выбранной модели\n","\n","3.3. Запуск сниппетов\n","\n","3.4. Анализ результатов"]},{"cell_type":"markdown","id":"e5060669","metadata":{"id":"e5060669"},"source":["### 3.1. Список используемых AI\n","\n","Использовались те же ассистенты: Gemini, ChatGPT, GigaChat.\n","\n","Промпт:\n","\n","Напиши Python код с использованием библиотеки transformers от Hugging Face для загрузки модели 'distilbert/distilgpt2'. Мне нужно получить доступ к матрицам весов одного из её слоев (например, первого слоя трансформера) как к numpy-массивам."]},{"cell_type":"markdown","id":"7b9967ae","metadata":{"id":"7b9967ae"},"source":["### 3.2. Сниппеты для скачивания выбранной модели"]},{"cell_type":"markdown","id":"6ca6dc9d","metadata":{"id":"6ca6dc9d"},"source":["Модель 1: Gemini (Google)"]},{"cell_type":"code","execution_count":1,"id":"30f9aad1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561,"referenced_widgets":["27d64ac3b8ee4e80b549a4deb99887d6","f6e3f45b78654bc1bf62dbc0035d05ac","0077fae5754d46509fbffe026853bddc","2d280c09d97d455fb348b0955d303544","beb348fc241440f6af2d0ec984fb89a2","4a3397edba7d4d8d81e85fe29e028b7b","8ca7d848dc43468a8a1d269fce7b8882","a03a90ef3fef4b03b151636b6f2f5bb3","34331f3e9fb046d58d4c265bd97200dd","abe93a97682c47e18021022f4f8cbff3","42b3ecd95d7d4cdfbc9e6c963feb98b7","328d2a20f36b48eebdbfb2e2cd78979d","2ad78c76ecdf4709b7d7afd3a4cd8756","79dd401853df4236beb13fb84bec2caf","7210634865fc49459702f13cffa7ea4f","8f16fc20eec346318aad57070aef55ba","a3ad51e153ff4c37a0804582fe26e6d0","c11810f46e9146da9bef9646600fe804","a3bcfc78703e471e80e9d218096856c3","1d1413f4e9094d2bbc5e948ef2e0998e","30968874167d4dcc903dea54cd1aac4e","7afffb7aebf241caa3d730eea52ef356","dfcfb4832b3944d098c5742696217058","f7832bf573ec486ab62aad6a82857af1","d6a92f3afae041c5968a26f764e21746","aa51970403d34ccba957c393be286176","c3671a2f1f30481f8757631e69d00ef4","d171878bcbb344f7a3cbd40f2d88b1d8","9f596ea855044fa99a287d6126aeb8c9","d400d3f68b8f44199d5d946e43803930","02060c039b524fb086f2f243c268b04c","be344238a4564d45b1e0d24846842e43","d7689b4d2dfc46d4aa462860e590580e"]},"id":"30f9aad1","executionInfo":{"status":"ok","timestamp":1745943657016,"user_tz":-180,"elapsed":41351,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"244f1b40-03c1-40d4-aeda-501b349bfb7b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27d64ac3b8ee4e80b549a4deb99887d6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"328d2a20f36b48eebdbfb2e2cd78979d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfcfb4832b3944d098c5742696217058"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Модель 'distilbert/distilgpt2' успешно загружена.\n","Общее количество параметров модели: 81912576\n","\n","Доступ к первому слою трансформера (индекс 0).\n","\n","Веса проекции QKV первого слоя attention:\n","  Тип: <class 'numpy.ndarray'>\n","  Размерность (shape): (768, 2304)\n","Веса смещения (bias) проекции QKV первого слоя attention:\n","  Тип: <class 'numpy.ndarray'>\n","  Размерность (shape): (2304,)\n","\n","Веса первого линейного слоя (c_fc) MLP первого слоя:\n","  Тип: <class 'numpy.ndarray'>\n","  Размерность (shape): (768, 3072)\n","Веса смещения (bias) первого линейного слоя (c_fc) MLP первого слоя:\n","  Тип: <class 'numpy.ndarray'>\n","  Размерность (shape): (3072,)\n"]}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import numpy as np\n","\n","# Идентификатор модели на Hugging Face\n","model_name = \"distilbert/distilgpt2\"\n","\n","try:\n","    # Загрузка модели\n","    # use_safetensors=True рекомендуется для более безопасной и быстрой загрузки\n","    model = AutoModelForCausalLM.from_pretrained(model_name, use_safetensors=True)\n","\n","    print(f\"Модель '{model_name}' успешно загружена.\")\n","    print(f\"Общее количество параметров модели: {sum(p.numel() for p in model.parameters())}\")\n","\n","    # Структура моделей на основе GPT-2 (включая DistilGPT2) обычно\n","    # содержит слои трансформера в атрибуте 'transformer.h'.\n","    # Получаем первый слой (индекс 0)\n","    if hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n","        first_transformer_layer = model.transformer.h[0]\n","        print(\"\\nДоступ к первому слою трансформера (индекс 0).\")\n","\n","        # Внутри слоя трансформера есть блоки внимания (attn) и MLP (mlp).\n","        # У них есть линейные слои с весами.\n","        # Получим, например, веса проекции запросов/ключей/значений (QKV)\n","        # и веса первого линейного слоя в MLP.\n","\n","        # Веса QKV проекции в блоке внимания\n","        if hasattr(first_transformer_layer, 'attn') and hasattr(first_transformer_layer.attn, 'c_attn'):\n","            qkv_weights_tensor = first_transformer_layer.attn.c_attn.weight.data\n","            qkv_weights_numpy = qkv_weights_tensor.cpu().numpy() # Перемещаем на CPU и конвертируем в numpy\n","            print(f\"\\nВеса проекции QKV первого слоя attention:\")\n","            print(f\"  Тип: {type(qkv_weights_numpy)}\")\n","            print(f\"  Размерность (shape): {qkv_weights_numpy.shape}\")\n","            # print(f\"  Несколько значений: {qkv_weights_numpy.flatten()[:10]}\") # Пример первых 10 значений\n","\n","            qkv_bias_tensor = first_transformer_layer.attn.c_attn.bias.data\n","            qkv_bias_numpy = qkv_bias_tensor.cpu().numpy()\n","            print(f\"Веса смещения (bias) проекции QKV первого слоя attention:\")\n","            print(f\"  Тип: {type(qkv_bias_numpy)}\")\n","            print(f\"  Размерность (shape): {qkv_bias_numpy.shape}\")\n","\n","        # Веса первого линейного слоя в блоке MLP\n","        if hasattr(first_transformer_layer, 'mlp') and hasattr(first_transformer_layer.mlp, 'c_fc'):\n","            ffn1_weights_tensor = first_transformer_layer.mlp.c_fc.weight.data\n","            ffn1_weights_numpy = ffn1_weights_tensor.cpu().numpy() # Перемещаем на CPU и конвертируем в numpy\n","            print(f\"\\nВеса первого линейного слоя (c_fc) MLP первого слоя:\")\n","            print(f\"  Тип: {type(ffn1_weights_numpy)}\")\n","            print(f\"  Размерность (shape): {ffn1_weights_numpy.shape}\")\n","            # print(f\"  Несколько значений: {ffn1_weights_numpy.flatten()[:10]}\") # Пример первых 10 значений\n","\n","            ffn1_bias_tensor = first_transformer_layer.mlp.c_fc.bias.data\n","            ffn1_bias_numpy = ffn1_bias_tensor.cpu().numpy()\n","            print(f\"Веса смещения (bias) первого линейного слоя (c_fc) MLP первого слоя:\")\n","            print(f\"  Тип: {type(ffn1_bias_numpy)}\")\n","            print(f\"  Размерность (shape): {ffn1_bias_numpy.shape}\")\n","\n","        # Можно аналогично получить веса других частей слоя, например:\n","        # Веса выходной проекции attention: first_transformer_layer.attn.c_proj.weight.data.cpu().numpy()\n","        # Веса второго линейного слоя MLP: first_transformer_layer.mlp.c_proj.weight.data.cpu().numpy()\n","        # Веса нормализации слоя: first_transformer_layer.ln_1.weight.data.cpu().numpy(), etc.\n","\n","    else:\n","        print(\"\\nНе удалось получить доступ к слоям трансформера в ожидаемой структуре.\")\n","        print(\"Возможно, структура модели отличается. Изучите объект 'model'.\")\n","\n","\n","except Exception as e:\n","    print(f\"Произошла ошибка при загрузке или доступе к модели: {e}\")"]},{"cell_type":"markdown","id":"38dea61d","metadata":{"id":"38dea61d"},"source":["Модель 2: ChatGPT (OpenAI)"]},{"cell_type":"code","execution_count":2,"id":"36c878d7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194,"referenced_widgets":["5b7b91975e44463dbd7a0d6a32830d40","ec89c79e89764efbbff65684f74e5fdb","ac2808e829b44ffba0156d216862a65e","da585288b935446f928d3d895d0b577d","f51fb06d3acc4d2faa7c2acd152e8e95","3ed251d72ac64ce690de474e801401e6","4a3441162ee7440ba90c2832799e5b44","9d3a6034af994907aa6be34385740979","0e590229574c41b1ba5d9521e51b9212","94a973bda0ba4256bd64930f7dd061f7","de6d5207618447dbb936955c49d78bfa","dba8f83a60894bb3902a852917bfe963","2e18d88b1579438ba0d71ac93970590d","c6cbb9a2ff36456a944c5da47b84aee5","6c6f5e49387f471880d56212e919f888","71f38f9d93da445fb7ee6480149a4fcc","e3e38a7239474591b342edbc478f4b97","b36bee95cc2e4cbf8cd47b6e53268ca5","9c0405a16a944e659e2b9a75f5a3114d","f3fa3e052177438fbb36744f7aab18d8","b34198d3831d4d6fb32e5523bb384dd3","05d8dcf08efa4e279d74fdee8e7374b2","df086bd1e0a24dfca0ac816115239e10","23a64687f20c433383658c19c2c7ae2c","4f435f0ebd2a46718eb438182c4c7b57","79bcecda94214b6fa7f61a864c4e9156","93685806e0444a80a309864334d27f7b","e9468471674c471cb6ab866078260f21","0817b5c995ee457bbc011a859aeab17b","f44a6501b1984b27ba088fdd846a632e","37753a1da816493fb359c85780b31ac6","bdb0414200904f5487c2760d91a397f9","290506aee2b44ab393726a42991aee9e","d9280c090c134fc09bd0554909c025ee","3bc4890e72b64f8babe2f990aa7e87d7","c29c3c9fc4844d29bd1ceff0553e02ba","847e5c4654114370842f8f33b9904b96","a8f15cae368c4d058aa46b19ed5baa1c","a6d42b4db6914e4eb63ca076da2bc931","02903f8e0c9e4e5e9e187991c0c246df","82ba4df2d26842d1904cccdbb0a303ab","aead40bd7263494fbd4f7588d2fc5879","45c8b5de1b0f42ef82c4bdd8aee3ca89","a891868e141143289a3ee9a16da90d36"]},"id":"36c878d7","executionInfo":{"status":"ok","timestamp":1745943658259,"user_tz":-180,"elapsed":1240,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"5d49a4c8-3a02-436c-c3f0-690cd79e9d4d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b7b91975e44463dbd7a0d6a32830d40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba8f83a60894bb3902a852917bfe963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df086bd1e0a24dfca0ac816115239e10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9280c090c134fc09bd0554909c025ee"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["QKV weight shape: (768, 2304)\n","Attention output proj weight shape: (768, 768)\n","Feedforward weight shape: (768, 3072)\n"]}],"source":["import torch\n","import numpy as np\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# Загрузка модели и токенизатора\n","model_name = 'distilbert/distilgpt2'\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Убедимся, что модель в режиме оценки\n","model.eval()\n","\n","# Извлечение первого слоя трансформера\n","# Для GPT-подобной модели это модельный блок в transformer.h\n","first_block = model.transformer.h[0]\n","\n","# Получим веса attention-слоя (например, матрицы для Q, K, V)\n","# Они находятся в: c_attn.weight\n","qkv_weights = first_block.attn.c_attn.weight.detach().cpu().numpy()\n","\n","# Альтернатива — вес output-проекции attention-а\n","attn_out_proj_weights = first_block.attn.c_proj.weight.detach().cpu().numpy()\n","\n","# Также можно получить веса feed-forward слоя\n","ffn_weights = first_block.mlp.c_fc.weight.detach().cpu().numpy()\n","\n","# Пример вывода форм\n","print(\"QKV weight shape:\", qkv_weights.shape)\n","print(\"Attention output proj weight shape:\", attn_out_proj_weights.shape)\n","print(\"Feedforward weight shape:\", ffn_weights.shape)"]},{"cell_type":"markdown","id":"a17d188a","metadata":{"id":"a17d188a"},"source":["Модель 3: DeepSeek"]},{"cell_type":"code","execution_count":11,"id":"f7dabfc9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"f7dabfc9","executionInfo":{"status":"error","timestamp":1745943952309,"user_tz":-180,"elapsed":179,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"4c2b429b-141b-48f9-a3d7-7090a7f03bfc"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'GPT2Model' object has no attribute 'transformer'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-536a68213a51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Получаем первый слой трансформера\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# У DistilGPT2 слои находятся в `transformer.h`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfirst_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Доступ к матрицам весов первого слоя:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'GPT2Model' object has no attribute 'transformer'"]}],"source":["from transformers import AutoModel\n","import numpy as np\n","\n","# Загружаем модель и её конфигурацию\n","model_name = \"distilgpt2\"\n","model = AutoModel.from_pretrained(model_name)\n","\n","# Переводим модель в режим оценки (отключаем dropout и т.д.)\n","model.eval()\n","\n","# Получаем первый слой трансформера\n","# У DistilGPT2 слои находятся в `transformer.h`\n","first_layer = model.transformer.h[0]\n","\n","# Доступ к матрицам весов первого слоя:\n","# 1. Матрицы внимания (query, key, value, output)\n","q_weights = first_layer.attention.q_lin.weight.data.numpy()  # (768, 768)\n","k_weights = first_layer.attention.k_lin.weight.data.numpy()  # (768, 768)\n","v_weights = first_layer.attention.v_lin.weight.data.numpy()  # (768, 768)\n","out_weights = first_layer.attention.out_lin.weight.data.numpy()  # (768, 768)\n","\n","# 2. Полносвязные слои (двухслойный MLP)\n","fc1_weights = first_layer.ffn.lin1.weight.data.numpy()  # (3072, 768)\n","fc2_weights = first_layer.ffn.lin2.weight.data.numpy()  # (768, 3072)\n","\n","# 3. Нормализация (LayerNorm)\n","ln1_weights = first_layer.sa_layer_norm.weight.data.numpy()  # (768,)\n","ln2_weights = first_layer.output_layer_norm.weight.data.numpy()  # (768,)\n","\n","# Пример вывода формы матриц\n","print(\"Query weights shape:\", q_weights.shape)\n","print(\"Key weights shape:\", k_weights.shape)\n","print(\"Value weights shape:\", v_weights.shape)\n","print(\"Output projection shape:\", out_weights.shape)\n","print(\"FFN fc1 shape:\", fc1_weights.shape)\n","print(\"FFN fc2 shape:\", fc2_weights.shape)\n","print(\"LayerNorm 1 weights shape:\", ln1_weights.shape)"]},{"cell_type":"markdown","id":"201abe2b","metadata":{"id":"201abe2b"},"source":["### 3.4. Анализ результатов\n","\n","Код, предоставленный Gemini и ChatGPT, успешно справился с задачей загрузки модели 'distilbert/distilgpt2' и извлечения матриц весов указанного слоя в виде numpy-массивов. Оба ассистента корректно использовали библиотеку `transformers` и методы для доступа к параметрам модели.\n","\n","Код от DeepSeek изначально содержал ошибку (`AttributeError: 'GPT2Model' object has no attribute 'transformer'`). Это произошло из-за неверного пути доступа к слоям модели (`model.transformer.h[0]` вместо `model.h[0]` для `AutoModel`, или использования `AutoModelForCausalLM` как в других примерах, где путь `model.transformer.h[0]` корректен). Это типичный пример галлюцинации LLM, когда модель генерирует код, основанный на общих паттернах (многие трансформеры имеют атрибут `transformer`), но не учитывает специфику конкретного класса (`AutoModel` для `distilgpt2` в данном случае) или предложенного способа загрузки. После исправления пути доступа к слоям код заработал."]},{"cell_type":"markdown","id":"a34d4af1","metadata":{"id":"a34d4af1"},"source":["---"]},{"cell_type":"markdown","id":"33a780f7","metadata":{"id":"33a780f7"},"source":["## Раздел 4. Первые галлюцинации\n","Если код после запуска не работает, получите у соответствующего AI-ассистента рекомендации по исправлению кода. Вставьте исправленный код в новую соответствующую ячейку. Запустите код и в случае, если код снова не работает, получите новые исправления. Продолжайте либо, пока код не заработает, либо пока AI-ассистент не начнёт слишком сильно галлюцинировать. Протоколируйте все диалоги в соответствующие ячейки. Проведите анализ полученных результатов в текущем разделе.\n","\n","В случае, если все модели отработали безупречно, вернитесь к этому разделу после промта по написанию методов рассчёта собственных значений матрицы (раздел 6) или оптимизации выбранной модели LLM при помощи методов поиска собственных значений и собственных векторов матрицы весов. (раздел 7)"]},{"cell_type":"markdown","id":"63171b0e","metadata":{"id":"63171b0e"},"source":["#### Справка: Когда LLM начинают галлюцинировать?\n","\n","**LLMs склонны к галлюцинациям во время написания кода, главным образом, в таких ситуациях:**\n","\n","1. **Неоднозначные или недостаточно определенные запросы**  \n","   - Если запрос расплывчатый (\"напишите алгоритм быстрой сортировки\"), то LLM может начать гадать и выдумывать детали.\n","2. **Редкие или незнакомые библиотеки, API или фреймворки**  \n","   - Если Вы спрашиваете о малоизвестном инструменте или совершенно новой версии библиотеки, LLM может \"придумать\" методы, классы или шаблоны использования на основе шаблонов, которые он видел в других местах.\n","3. **Междоменные запросы**  \n","   - При объединении технологий (например, \"использовать модели SQLAlchemy внутри конвейера TensorFlow\") могут возникнуть галлюцинации с API, которых на самом деле не существует.\n","4. **Устаревшие или будущие знания**  \n","   - Если что-то изменилось после завершения обучения модели (например, новые возможности версии Python), она может придумать поведение, которое \"ожидает\", основываясь на тенденциях.\n","5. **Сложные многоэтапные задачи**  \n","   - В более длинных цепочках (например, при полной настройке приложения) накапливаются ошибки - пропущенный импорт, неправильные типы, воображаемые функции и т.д.\n","6. **Когда вас просят оптимизировать, упростить или сильно обобщить**  \n","   - \"Напишите наиболее эффективную систему кэширования\" — это может привести к созданию идеализированных методов, которые звучат правдоподобно, но не являются реальными.\n","7. **Слишком самоуверенные формулировки в запросах**  \n","   - Если вы спросите \"Дайте мне точный вызов API для...\" с полной уверенностью, модель может выдать очень уверенный, но совершенно неверный ответ.\n","\n","**Как распознать галлюцинации, когда LLMs пишут код:**\n","\n","- **Сверьтесь с официальной документацией.**  \n","  Всегда сверяйте названия функций, сигнатуры методов и использование библиотек с реальной документацией.\n","\n","- **Запустите и протестируйте код на ранней стадии.**  \n","  Даже небольшой пример (модульный тест, выполнение скрипта) может сразу выявить недостоверные детали.\n","\n","- **Используйте средства проверки типов и линтеры.**  \n","  Такие инструменты, как \"mypy\", \"pylint\" или \"eslint\", часто обнаруживают (*выдуманные*) ошибочные API, неправильный импорт и т.д.\n","\n","- **Задавайте дополнительные вопросы.**  \n","  Если вы не уверены, вы можете спросить у LLM: \"Вы уверены, что `foo.bar()` существует? Можете ли вы показать документацию?\". Но в последних версиях LLM поголовно научились нагло врать, наставать и выдумывать ссылки.\n","\n","- **Будьте подозрительны к слишком точным ответам.**  \n","  Реальный код часто требует обработки ошибок, нестандартных ситуаций, шагов по настройке. Галлюцинированный код часто выглядит \"слишком чистым\".\n","\n","- **Делайте подсказки конкретными.**  \n","  Сужение задачи снижает вероятность того, что модель ошибется в своих предположениях."]},{"cell_type":"markdown","id":"fad8c772","metadata":{"id":"fad8c772"},"source":["Модель 1: DeepSeek"]},{"cell_type":"code","execution_count":12,"id":"015fafa0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"015fafa0","executionInfo":{"status":"error","timestamp":1745943974044,"user_tz":-180,"elapsed":218,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"cc98b562-c048-4633-edc6-32b232523115"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'GPT2Attention' object has no attribute 'q_lin'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-dbf72d00a79c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Доступ к матрицам весов:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 1. Матрицы внимания (query, key, value, output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mq_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_lin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (768, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mk_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_lin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (768, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mv_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_lin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (768, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'GPT2Attention' object has no attribute 'q_lin'"]}],"source":["from transformers import AutoModel\n","import numpy as np\n","\n","# Загружаем модель\n","model_name = \"distilgpt2\"\n","model = AutoModel.from_pretrained(model_name)\n","model.eval()  # Переводим в режим оценки\n","\n","# Получаем первый слой трансформера\n","# У GPT2 и DistilGPT2 слои находятся прямо в `.h`\n","first_layer = model.h[0]  # <-- Исправлено здесь!\n","\n","# Доступ к матрицам весов:\n","# 1. Матрицы внимания (query, key, value, output)\n","q_weights = first_layer.attn.q_lin.weight.data.numpy()  # (768, 768)\n","k_weights = first_layer.attn.k_lin.weight.data.numpy()  # (768, 768)\n","v_weights = first_layer.attn.v_lin.weight.data.numpy()  # (768, 768)\n","out_weights = first_layer.attn.out_lin.weight.data.numpy()  # (768, 768)\n","\n","# 2. Полносвязные слои (MLP)\n","fc1_weights = first_layer.mlp.lin1.weight.data.numpy()  # (3072, 768)\n","fc2_weights = first_layer.mlp.lin2.weight.data.numpy()  # (768, 3072)\n","\n","# 3. Нормализация (LayerNorm)\n","ln1_weights = first_layer.ln_1.weight.data.numpy()  # (768,)\n","ln2_weights = first_layer.ln_2.weight.data.numpy()  # (768,)\n","\n","# Вывод форм матриц\n","print(\"Query weights shape:\", q_weights.shape)\n","print(\"Key weights shape:\", k_weights.shape)\n","print(\"Value weights shape:\", v_weights.shape)\n","print(\"Output projection shape:\", out_weights.shape)\n","print(\"FFN fc1 shape:\", fc1_weights.shape)\n","print(\"FFN fc2 shape:\", fc2_weights.shape)\n","print(\"LayerNorm 1 weights shape:\", ln1_weights.shape)"]},{"cell_type":"code","source":["from transformers import AutoModel\n","import numpy as np\n","import torch\n","\n","# Загружаем модель\n","model_name = \"distilgpt2\"\n","model = AutoModel.from_pretrained(model_name)\n","model.eval()\n","\n","# Получаем первый слой трансформера\n","first_layer = model.h[0]\n","\n","# 1. Веса механизма внимания\n","# У GPT2/DistilGPT2 Q, K, V объединены в одну матрицу c_attn\n","c_attn_weights = first_layer.attn.c_attn.weight.data  # (768, 2304 = 3*768)\n","c_attn_bias = first_layer.attn.c_attn.bias.data      # (2304,)\n","\n","# Разделяем на Q, K, V\n","dim = c_attn_weights.shape[0]  # 768\n","q_weights = c_attn_weights[:, :dim].numpy()          # (768, 768)\n","k_weights = c_attn_weights[:, dim:2*dim].numpy()     # (768, 768)\n","v_weights = c_attn_weights[:, 2*dim:].numpy()        # (768, 768)\n","\n","# Веса выходной проекции внимания\n","out_weights = first_layer.attn.c_proj.weight.data.numpy()  # (768, 768)\n","\n","# 2. Веса MLP (полносвязные слои)\n","mlp_fc1 = first_layer.mlp.c_fc.weight.data.numpy()    # (3072, 768)\n","mlp_fc2 = first_layer.mlp.c_proj.weight.data.numpy()  # (768, 3072)\n","\n","# 3. Веса LayerNorm\n","ln_1_weights = first_layer.ln_1.weight.data.numpy()   # (768,)\n","ln_2_weights = first_layer.ln_2.weight.data.numpy()   # (768,)\n","\n","# Вывод форм матриц\n","print(\"Q weights shape:\", q_weights.shape)\n","print(\"K weights shape:\", k_weights.shape)\n","print(\"V weights shape:\", v_weights.shape)\n","print(\"Output projection shape:\", out_weights.shape)\n","print(\"MLP fc1 shape:\", mlp_fc1.shape)\n","print(\"MLP fc2 shape:\", mlp_fc2.shape)\n","\n","target_matrix = q_weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrpNa5I8Xthl","executionInfo":{"status":"ok","timestamp":1745945189490,"user_tz":-180,"elapsed":205,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"8aae8a92-34d2-4bd1-dbd2-c04327a4bc58"},"id":"UrpNa5I8Xthl","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Q weights shape: (768, 768)\n","K weights shape: (768, 768)\n","V weights shape: (768, 768)\n","Output projection shape: (768, 768)\n","MLP fc1 shape: (768, 3072)\n","MLP fc2 shape: (3072, 768)\n"]}]},{"cell_type":"markdown","id":"5a135f37","metadata":{"id":"5a135f37"},"source":["---"]},{"cell_type":"markdown","id":"bcdaff9f","metadata":{"id":"bcdaff9f"},"source":["## Раздел 5. Набросаем код методов самостоятельно из готовой документации\n","\n","Реализуйте расчёт собственных значений матриц весов любого слоя при помощи известных Вам методов самостоятельно, используя стандартные библиотеки Python.\n","\n","Выполните это задание самостоятельно, а не при помощи ассистентов (**любых**, включая GitHub Copilot autocomplite, его можно отключить в настройках справа внизу, Google Colab Gemini тоже можнот отключить в настройках \"Инструменты\"-\"ИИ-функции\"-\"Предлагать подсказки ИИ для дополнения кода\"), чтобы можно было корректно сравнить результаты стандартных библиотек и сниппетов, которые предложат Вам ассистенты далее.\n","\n","\n","| Метод | Функция Python | Библиотека | Ссылка на документацию |\n","|---|---|---|---|\n","|Power Method (Dominant Eigenvalue) | Manual (template provided) | Custom/Numpy | [Tutorial](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/Approximating_Eigenvalues.html#power-method) or [template](https://en.wikipedia.org/wiki/Power_iteration#Numerical_example) — implement with `numpy.dot` |\n","|Shifted Power Method | Manual + `numpy.linalg.solve` | Numpy | [Tutorial](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/Approximating_Eigenvalues.html) |\n","|QR Algorithm (Full Spectrum) | `scipy.linalg.eig` or `numpy.linalg.eig` | Scipy/Numpy | [scipy.linalg.eig](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eig.html) / [numpy.linalg.eig](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html) |\n","|Full QR Decomposition (optional deeper understanding) | `numpy.linalg.qr` | Numpy | [numpy.linalg.qr](https://numpy.org/doc/stable/reference/generated/numpy.linalg.qr.html) |"]},{"cell_type":"code","execution_count":21,"id":"773b4940","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"773b4940","executionInfo":{"status":"ok","timestamp":1745944555375,"user_tz":-180,"elapsed":5,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"a013eefb-6c12-4230-9676-4bb2a9827b7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Матрица весов W:\n"," [[ 0.49671415 -0.1382643   0.64768854  1.52302986]\n"," [-0.23415337 -0.23413696  1.57921282  0.76743473]\n"," [-0.46947439  0.54256004 -0.46341769 -0.46572975]\n"," [ 0.24196227 -1.91328024 -1.72491783 -0.56228753]]\n","\n","Собственные значения:\n"," [ 1.43750501+0.j         -0.79407997+0.j         -0.70327653+1.06686096j\n"," -0.70327653-1.06686096j]\n","\n","Собственные векторы (столбцы):\n"," [[ 0.70678858+0.j         -0.38383401+0.j         -0.37825022-0.44822856j\n","  -0.37825022+0.44822856j]\n"," [-0.18167634+0.j          0.48849804+0.j          0.02871948-0.49840163j\n","   0.02871948+0.49840163j]\n"," [-0.36764002+0.j         -0.51649525+0.j         -0.03351373+0.1010031j\n","  -0.03351373-0.1010031j ]\n"," [ 0.57644117+0.j          0.58929939+0.j          0.6288594 +0.j\n","   0.6288594 -0.j        ]]\n"]}],"source":["import numpy as np\n","\n","def power_iteration(matrix, num_simulations: int = 100):\n","    n = matrix.shape[0]\n","    # Инициализируем случайный вектор\n","    b_k = np.random.rand(n)\n","\n","    for _ in range(num_simulations):\n","        # Вычисляем произведение матрицы на вектор\n","        b_k1 = np.dot(matrix, b_k)\n","\n","        # Нормализуем вектор\n","        b_k1_norm = np.linalg.norm(b_k1)\n","        b_k = b_k1 / b_k1_norm\n","\n","    # Собственное значение Рэлея\n","    eigenvalue = np.dot(b_k.T, np.dot(matrix, b_k)) / np.dot(b_k.T, b_k)\n","    return eigenvalue, b_k\n","\n","# Генерация случайной матрицы весов (например, 4x4)\n","np.random.seed(42)\n","W = np.random.randn(4, 4)\n","\n","dominant_eigenvalue, dominant_eigenvector = power_iteration(A)\n","\n","# Расчет собственных значений и векторов\n","eigenvalues_np, eigenvectors_np = np.linalg.eig(W)\n","\n","# Вывод результатов\n","print(\"Матрица весов W:\\n\", W)\n","print(\"\\nСобственные значения:\\n\", eigenvalues_np)\n","print(\"\\nСобственные векторы (столбцы):\\n\", eigenvectors_np)"]},{"cell_type":"markdown","id":"9d17fb7e","metadata":{"id":"9d17fb7e"},"source":["---"]},{"cell_type":"markdown","id":"b22ec577","metadata":{"id":"b22ec577"},"source":["## Раздел 6. AI-ассистенты пишут код для расчёта собственных значений и векторов матриц\n","6.1. Напишите промпт для получения сниппетов методов расчёта собственных значений и векторов матриц.\n","\n","6.2. Сниппеты для расчёта собственных значений и векторов матриц\n","\n","6.3. Запуск сниппетов против любой выбранной Вами матрицы\n","\n","6.4. Анализ результатов"]},{"cell_type":"markdown","id":"c178daa2","metadata":{"id":"c178daa2"},"source":["### 6.1 Ваш промпт\n","\n","Напиши функции Python для вычисления:\n","1. Доминантного собственного значения и соответствующего собственного вектора матрицы с использованием степенного метода (power iteration).\n","2. Всех собственных значений и собственных векторов матрицы с использованием функции из библиотеки NumPy или SciPy.\n","\n","Продемонстрируй их работу на небольшой тестовой матрице. Используй numpy для матричных операций."]},{"cell_type":"markdown","id":"0dadb9ce","metadata":{"id":"0dadb9ce"},"source":["### 6.2. Сниппеты для расчёта собственных значений и векторов матриц"]},{"cell_type":"markdown","id":"677cf1f0","metadata":{"id":"677cf1f0"},"source":["Модель 1: Gemini (Google)"]},{"cell_type":"code","execution_count":20,"id":"a12c1217","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a12c1217","executionInfo":{"status":"ok","timestamp":1745944508531,"user_tz":-180,"elapsed":42,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"28667d76-1ba8-4231-d8ce-60623c40c390"},"outputs":[{"output_type":"stream","name":"stdout","text":["Тестовая матрица:\n","[[4 1]\n"," [2 3]]\n","------------------------------\n","Результат степенного метода (нахождение доминантного собственного значения/вектора):\n","  Доминантное собственное значение: 5.000000285665802\n","  Соответствующий собственный вектор: [0.70710698 0.70710658]\n","\n","  Проверка (A * v vs lambda * v):\n","    A * v: [3.53553451 3.5355337 ]\n","    lambda * v: [3.53553512 3.5355331 ]\n","    Разница (норма): 8.569982249548373e-07\n","------------------------------\n","Результат с использованием np.linalg.eig (все собственные значения/вектора):\n","  Все собственные значения: [5. 2.]\n","  Соответствующие собственные векторы (по столбцам):\n","[[ 0.70710678 -0.4472136 ]\n"," [ 0.70710678  0.89442719]]\n","\n","  Проверка для всех пар (A * v[:, i] vs lambda[i] * v[:, i]):\n","    Пара 1:\n","      Собственное значение: 5.0\n","      Собственный вектор: [0.70710678 0.70710678]\n","      A * v: [3.53553391 3.53553391]\n","      lambda * v: [3.53553391 3.53553391]\n","      Разница (норма): 0.0\n","----------\n","    Пара 2:\n","      Собственное значение: 2.0\n","      Собственный вектор: [-0.4472136   0.89442719]\n","      A * v: [-0.89442719  1.78885438]\n","      lambda * v: [-0.89442719  1.78885438]\n","      Разница (норма): 2.220446049250313e-16\n","----------\n","\n","==============================\n","Тестовая матрица 3x3:\n","[[ 3 -1  0]\n"," [-1  2 -1]\n"," [ 0 -1  3]]\n","------------------------------\n","Результат степенного метода (нахождение доминантного собственного значения/вектора):\n","  Доминантное собственное значение: 3.9999999999943894\n","  Соответствующий собственный вектор: [ 0.57735194 -0.57735027  0.57734859]\n","\n","  Проверка (A * v vs lambda * v):\n","    A * v: [ 2.3094061  -2.30940108  2.30939605]\n","    lambda * v: [ 2.30940778 -2.30940108  2.30939438]\n","    Разница (норма): 2.368600473618041e-06\n","------------------------------\n","Результат с использованием np.linalg.eig (все собственные значения/вектора):\n","  Все собственные значения: [1. 3. 4.]\n","  Соответствующие собственные векторы (по столбцам):\n","[[ 4.08248290e-01 -7.07106781e-01  5.77350269e-01]\n"," [ 8.16496581e-01  4.02240178e-16 -5.77350269e-01]\n"," [ 4.08248290e-01  7.07106781e-01  5.77350269e-01]]\n"]}],"source":["import numpy as np\n","\n","def power_iteration_gemini(matrix, num_iterations=1000, tolerance=1e-6):\n","    \"\"\"\n","    Вычисляет доминантное собственное значение и собственный вектор\n","    матрицы с использованием степенного метода.\n","\n","    Аргументы:\n","        matrix (np.ndarray): Квадратная NumPy матрица.\n","        num_iterations (int): Максимальное количество итераций.\n","        tolerance (float): Критерий остановки по норме разности векторов.\n","\n","    Возвращает:\n","        tuple: (доминантное_собственное_значение, доминантный_собственный_вектор)\n","               или (None, None), если метод не сошелся в пределах итераций.\n","    \"\"\"\n","    n = matrix.shape[0]\n","    if matrix.shape[1] != n:\n","        raise ValueError(\"Матрица должна быть квадратной.\")\n","\n","    # 1. Инициализировать случайный начальный вектор\n","    # Убедимся, что вектор не нулевой\n","    eigenvector = np.random.rand(n)\n","    # Нормализовать вектор\n","    eigenvector = eigenvector / np.linalg.norm(eigenvector)\n","\n","    dominant_eigenvalue = None\n","\n","    # Итеративный процесс\n","    for _ in range(num_iterations):\n","        # 2. Вычислить произведение матрицы на вектор (Av_k)\n","        Av = np.dot(matrix, eigenvector)\n","\n","        # 3. Оценить собственное значение (используя норму Av_k)\n","        # Норма Av_k сходится к абсолютному значению доминантного собственного значения\n","        Av_norm = np.linalg.norm(Av)\n","\n","        # 4. Нормализовать новый вектор (v_{k+1} = Av_k / ||Av_k||)\n","        new_eigenvector = Av / Av_norm\n","\n","        # 5. Проверить сходимость\n","        # Сравниваем новый вектор с предыдущим\n","        if np.linalg.norm(new_eigenvector - eigenvector) < tolerance:\n","             # Вычисляем собственное значение более точно с помощью отношения Рэлея\n","             # для нормализованного вектора\n","             dominant_eigenvalue = np.dot(new_eigenvector.T, np.dot(matrix, new_eigenvector))\n","             return dominant_eigenvalue, new_eigenvector\n","\n","        # Обновить вектор для следующей итерации\n","        eigenvector = new_eigenvector\n","\n","    # Если метод не сошелся за num_iterations\n","    print(f\"Предупреждение: Степенной метод не сошелся за {num_iterations} итераций.\")\n","    # В случае несходимости вернем последнюю оценку и векторы\n","    # Или можно вернуть None, None\n","    dominant_eigenvalue = np.dot(eigenvector.T, np.dot(matrix, eigenvector)) # Последняя оценка\n","    return dominant_eigenvalue, eigenvector # Возвращаем последний вектор и его оценку с/з\n","\n","def get_all_eigen_np(matrix):\n","    \"\"\"\n","    Вычисляет все собственные значения и собственные векторы матрицы\n","    с использованием функции из библиотеки NumPy.\n","\n","    Аргументы:\n","        matrix (np.ndarray): Квадратная NumPy матрица.\n","\n","    Возвращает:\n","        tuple: (собственные_значения, собственные_векторы)\n","               где собственные_значения - массив собственных значений,\n","               а собственные_векторы - матрица, столбцами которой являются\n","               соответствующие собственные векторы.\n","    \"\"\"\n","    if matrix.shape[0] != matrix.shape[1]:\n","        raise ValueError(\"Матрица должна быть квадратной.\")\n","\n","    # Используем функцию np.linalg.eig()\n","    eigenvalues, eigenvectors = np.linalg.eig(matrix)\n","\n","    return eigenvalues, eigenvectors\n","\n","# --- Демонстрация работы ---\n","\n","# Создадим небольшую тестовую матрицу\n","# Например, матрица 2x2 с известными собственными значениями\n","# Матрица A = [[4, 1], [2, 3]]\n","# Собственные значения: lambda1 = 5, lambda2 = 2\n","test_matrix = np.array([[4, 1],\n","                        [2, 3]])\n","\n","print(\"Тестовая матрица:\")\n","print(test_matrix)\n","print(\"-\" * 30)\n","\n","# Демонстрация степенного метода\n","print(\"Результат степенного метода (нахождение доминантного собственного значения/вектора):\")\n","dominant_val_pi, dominant_vec_pi = power_iteration_gemini(test_matrix)\n","\n","if dominant_val_pi is not None:\n","    print(f\"  Доминантное собственное значение: {dominant_val_pi}\")\n","    print(f\"  Соответствующий собственный вектор: {dominant_vec_pi}\")\n","\n","    # Проверка: A * v = lambda * v\n","    Av = np.dot(test_matrix, dominant_vec_pi)\n","    lambdav = dominant_val_pi * dominant_vec_pi\n","    print(\"\\n  Проверка (A * v vs lambda * v):\")\n","    print(f\"    A * v: {Av}\")\n","    print(f\"    lambda * v: {lambdav}\")\n","    print(f\"    Разница (норма): {np.linalg.norm(Av - lambdav)}\") # Должна быть близка к нулю\n","\n","print(\"-\" * 30)\n","\n","# Демонстрация вычисления всех собственных значений/векторов с помощью NumPy\n","print(\"Результат с использованием np.linalg.eig (все собственные значения/вектора):\")\n","all_vals, all_vecs = get_all_eigen_np(test_matrix)\n","\n","print(f\"  Все собственные значения: {all_vals}\")\n","print(\"  Соответствующие собственные векторы (по столбцам):\")\n","print(all_vecs)\n","\n","# Проверка для всех пар (опционально)\n","print(\"\\n  Проверка для всех пар (A * v[:, i] vs lambda[i] * v[:, i]):\")\n","for i in range(len(all_vals)):\n","    eigenvalue = all_vals[i]\n","    eigenvector = all_vecs[:, i] # Получаем i-й столбец как вектор\n","\n","    Av = np.dot(test_matrix, eigenvector)\n","    lambdav = eigenvalue * eigenvector\n","\n","    print(f\"    Пара {i+1}:\")\n","    print(f\"      Собственное значение: {eigenvalue}\")\n","    print(f\"      Собственный вектор: {eigenvector}\")\n","    print(f\"      A * v: {Av}\")\n","    print(f\"      lambda * v: {lambdav}\")\n","    print(f\"      Разница (норма): {np.linalg.norm(Av - lambdav)}\") # Должна быть близка к нулю\n","    print(\"-\" * 10)\n","\n","# Попробуем другую матрицу 3x3\n","test_matrix_3x3 = np.array([[3, -1, 0],\n","                           [-1, 2, -1],\n","                           [0, -1, 3]])\n","\n","print(\"\\n\" + \"=\" * 30)\n","print(\"Тестовая матрица 3x3:\")\n","print(test_matrix_3x3)\n","print(\"-\" * 30)\n","\n","print(\"Результат степенного метода (нахождение доминантного собственного значения/вектора):\")\n","dominant_val_pi_3x3, dominant_vec_pi_3x3 = power_iteration_gemini(test_matrix_3x3)\n","\n","if dominant_val_pi_3x3 is not None:\n","    print(f\"  Доминантное собственное значение: {dominant_val_pi_3x3}\")\n","    print(f\"  Соответствующий собственный вектор: {dominant_vec_pi_3x3}\")\n","    # Проверка\n","    Av_3x3 = np.dot(test_matrix_3x3, dominant_vec_pi_3x3)\n","    lambdav_3x3 = dominant_val_pi_3x3 * dominant_vec_pi_3x3\n","    print(\"\\n  Проверка (A * v vs lambda * v):\")\n","    print(f\"    A * v: {Av_3x3}\")\n","    print(f\"    lambda * v: {lambdav_3x3}\")\n","    print(f\"    Разница (норма): {np.linalg.norm(Av_3x3 - lambdav_3x3)}\")\n","\n","print(\"-\" * 30)\n","print(\"Результат с использованием np.linalg.eig (все собственные значения/вектора):\")\n","all_vals_3x3, all_vecs_3x3 = get_all_eigen_np(test_matrix_3x3)\n","\n","print(f\"  Все собственные значения: {all_vals_3x3}\")\n","print(\"  Соответствующие собственные векторы (по столбцам):\")\n","print(all_vecs_3x3)"]},{"cell_type":"markdown","id":"f91e330f","metadata":{"id":"f91e330f"},"source":["Модель 2: ChatGPT (OpenAI)"]},{"cell_type":"code","execution_count":22,"id":"189121a9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"189121a9","executionInfo":{"status":"ok","timestamp":1745944692462,"user_tz":-180,"elapsed":25,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"4c65eb4e-4189-4aca-94a3-86e3772c9917"},"outputs":[{"output_type":"stream","name":"stdout","text":["Доминирующее собственное значение (степенной метод): 5.0\n","Соответствующий собственный вектор: [0.70710678 0.70710678]\n","\n","Все собственные значения (numpy): [5. 2.]\n","Все собственные векторы (numpy):\n"," [[ 0.70710678 -0.4472136 ]\n"," [ 0.70710678  0.89442719]]\n"]}],"source":["import numpy as np\n","\n","def power_iteration_chatgpt(A, num_iters=1000, tol=1e-9):\n","    \"\"\"\n","    Степенной метод для поиска доминирующего собственного значения и вектора.\n","    \"\"\"\n","    n, _ = A.shape\n","    b_k = np.random.rand(n)\n","    b_k /= np.linalg.norm(b_k)  # Нормализация\n","\n","    for _ in range(num_iters):\n","        # Умножаем A на текущий вектор\n","        b_k1 = A @ b_k\n","\n","        # Нормализуем\n","        b_k1_norm = np.linalg.norm(b_k1)\n","        b_k1 /= b_k1_norm\n","\n","        # Проверка сходимости\n","        if np.linalg.norm(b_k1 - b_k) < tol:\n","            break\n","\n","        b_k = b_k1\n","\n","    # Оценка собственного значения\n","    eigenvalue = (b_k.T @ A @ b_k)  # Релеевское частное\n","    eigenvector = b_k\n","    return eigenvalue, eigenvector\n","\n","def find_all_eigenvalues_vectors_numpy(A):\n","    \"\"\"\n","    Вычисление всех собственных значений и векторов.\n","    \"\"\"\n","    eigenvalues, eigenvectors = np.linalg.eig(A)\n","    return eigenvalues, eigenvectors\n","\n","# === Пример использования ===\n","A = np.array([\n","    [4, 1],\n","    [2, 3]\n","], dtype=float)\n","\n","# Степенной метод\n","dom_val, dom_vec = power_iteration(A)\n","print(\"Доминирующее собственное значение (степенной метод):\", dom_val)\n","print(\"Соответствующий собственный вектор:\", dom_vec)\n","\n","# Полная декомпозиция\n","eigvals, eigvecs = find_all_eigenvalues_vectors_numpy(A)\n","print(\"\\nВсе собственные значения (numpy):\", eigvals)\n","print(\"Все собственные векторы (numpy):\\n\", eigvecs)"]},{"cell_type":"markdown","id":"56d519c8","metadata":{"id":"56d519c8"},"source":["Модель 3: DeepSeek"]},{"cell_type":"code","execution_count":23,"id":"e26b9467","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e26b9467","executionInfo":{"status":"ok","timestamp":1745944695278,"user_tz":-180,"elapsed":19,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"09240597-3556-450b-cf54-34feb4fa37de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Доминантное собственное значение (степенной метод): 4.6751308705666474\n","Соответствующий собственный вектор: [ 0.88765034  0.42713229 -0.17214786]\n","\n","Все собственные значения (NumPy): [0.78568026 4.67513087 3.53918887]\n","Все собственные векторы (по столбцам):\n"," [[-0.39711255  0.88765034 -0.23319198]\n"," [ 0.52065737  0.42713229  0.73923874]\n"," [-0.75578934 -0.17214786  0.63178128]]\n","\n","Проверка A*v == λ*v: True\n"]}],"source":["import numpy as np\n","\n","def power_method_deepseek(A, num_iterations=100, tol=1e-10):\n","    \"\"\"\n","    Вычисляет доминантное собственное значение и соответствующий собственный вектор матрицы A.\n","\n","    Параметры:\n","        A : numpy.ndarray\n","            Квадратная матрица.\n","        num_iterations : int\n","            Максимальное число итераций.\n","        tol : float\n","            Критерий остановки (изменение нормы вектора).\n","\n","    Возвращает:\n","        eigenvalue : float\n","            Доминантное собственное значение.\n","        eigenvector : numpy.ndarray\n","            Соответствующий собственный вектор (нормированный).\n","    \"\"\"\n","    n = A.shape[0]\n","    eigenvector = np.random.rand(n)  # Начальное приближение\n","    eigenvector = eigenvector / np.linalg.norm(eigenvector)\n","\n","    for _ in range(num_iterations):\n","        old_vector = eigenvector.copy()\n","        eigenvector = A @ eigenvector\n","        eigenvector = eigenvector / np.linalg.norm(eigenvector)\n","\n","        # Проверка сходимости\n","        if np.linalg.norm(eigenvector - old_vector) < tol:\n","            break\n","\n","    eigenvalue = np.dot(eigenvector, A @ eigenvector)\n","    return eigenvalue, eigenvector\n","\n","def get_eigen_numpy_deepseek(A):\n","    \"\"\"\n","    Вычисляет все собственные значения и векторы матрицы A.\n","\n","    Параметры:\n","        A : numpy.ndarray\n","            Квадратная матрица.\n","\n","    Возвращает:\n","        eigenvalues : numpy.ndarray\n","            Массив собственных значений.\n","        eigenvectors : numpy.ndarray\n","            Матрица, где каждый столбец — собственный вектор.\n","    \"\"\"\n","    eigenvalues, eigenvectors = np.linalg.eig(A)\n","    return eigenvalues, eigenvectors\n","\n","# Тестовая матрица 3x3\n","A = np.array([[4, 1, -1],\n","              [1, 3, 1],\n","              [-1, 1, 2]])\n","\n","# 1. Степенной метод\n","dom_eigenvalue, dom_eigenvector = power_method_deepseek(A)\n","print(\"Доминантное собственное значение (степенной метод):\", dom_eigenvalue)\n","print(\"Соответствующий собственный вектор:\", dom_eigenvector)\n","\n","# 2. Полное разложение\n","eigenvalues, eigenvectors = full_eigen_decomposition(A)\n","print(\"\\nВсе собственные значения (NumPy):\", eigenvalues)\n","print(\"Все собственные векторы (по столбцам):\\n\", eigenvectors)\n","\n","# Проверка: A * v = λ * v для первого собственного вектора\n","first_eigenvector = eigenvectors[:, 0]\n","first_eigenvalue = eigenvalues[0]\n","print(\"\\nПроверка A*v == λ*v:\", np.allclose(A @ first_eigenvector, first_eigenvalue * first_eigenvector))"]},{"cell_type":"markdown","id":"d7f50616","metadata":{"id":"d7f50616"},"source":["### 6.3. Запуск сниппетов на любой выбранной матрице и численное сравнение с вашей реализацией"]},{"cell_type":"code","execution_count":24,"id":"38af45ba","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38af45ba","executionInfo":{"status":"ok","timestamp":1745944704431,"user_tz":-180,"elapsed":55,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"44079fee-fd23-4cbf-f7e2-1eab88d7a5fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Сравнение реализаций на матрице A ---\n","Матрица A:\n","[[-0.54438272  0.11092259 -1.15099358  0.37569802]\n"," [-0.60063869 -0.29169375 -0.60170661  1.85227818]\n"," [-0.01349722 -1.05771093  0.82254491 -1.22084365]\n"," [ 0.2088636  -1.95967012 -1.32818605  0.19686124]]\n","\n","1. Собственная реализация (Раздел 5):\n","   Все с.з. (numpy.linalg.eig): [ 1.437505+0.j       -0.79408 +0.j       -0.703277+1.066861j\n"," -0.703277-1.066861j]\n","\n","2. Реализация Gemini:\n","   Доминантное с.з. (степенной метод): 1.751437\n","   Все с.з. (numpy.linalg.eig): [ 1.751437+0.j      -0.380741+1.67338j -0.380741-1.67338j\n"," -0.806625+0.j     ]\n","   Разница доминантных с.з.: 2.92e+00\n","   Разница всех с.з. (норма): 1.02e+00\n","\n","3. Реализация ChatGPT:\n","   Доминантное с.з. (степенной метод): 1.751437\n","   Все с.з. (numpy.linalg.eig): [ 1.751437+0.j      -0.380741+1.67338j -0.380741-1.67338j\n"," -0.806625+0.j     ]\n","   Разница доминантных с.з.: 2.92e+00\n","   Разница всех с.з. (норма): 1.02e+00\n","\n","4. Реализация DeepSeek:\n","   Доминантное с.з. (степенной метод): 1.662345\n","   Все с.з. (numpy.linalg.eig): [ 1.751437+0.j      -0.380741+1.67338j -0.380741-1.67338j\n"," -0.806625+0.j     ]\n","   Разница доминантных с.з.: 3.01e+00\n","   Разница всех с.з. (норма): 1.02e+00\n"]}],"source":["A = np.random.randn(4, 4)\n","\n","print(\"\\n--- Сравнение реализаций на матрице A ---\")\n","print(f\"Матрица A:\\n{A}\")\n","\n","# Расчет собственных значений и векторов\n","eigenvalues, eigenvectors = np.linalg.eig(W)\n","\n","# 1. Собственная реализация (из Раздела 5)\n","print(\"\\n1. Собственная реализация (Раздел 5):\")\n","print(f\"   Все с.з. (numpy.linalg.eig): {np.round(eigenvalues, 6)}\")\n","\n","# 2. Gemini\n","print(\"\\n2. Реализация Gemini:\")\n","try:\n","    dom_eigval_g_A, _ = power_iteration_gemini(A)\n","    all_eigvals_g_A, _ = get_all_eigen_np(A)\n","    all_eigvals_g_A_sorted = np.sort(np.abs(all_eigvals_g_A))[::-1] # Сортировка по модулю для сравнения\n","    print(f\"   Доминантное с.з. (степенной метод): {dom_eigval_g_A:.6f}\")\n","    print(f\"   Все с.з. (numpy.linalg.eig): {np.round(np.sort(all_eigvals_g_A)[::-1], 6)}\") # Сортируем для наглядности\n","    print(f\"   Разница доминантных с.з.: {np.abs(dominant_eigenvalue - dom_eigval_g_A):.2e}\")\n","    print(f\"   Разница всех с.з. (норма): {np.linalg.norm(np.sort(eigenvalues_np) - np.sort(all_eigvals_g_A)):.2e}\")\n","except Exception as e:\n","    print(f\"   Ошибка при выполнении кода Gemini: {e}\")\n","\n","\n","# 3. ChatGPT\n","print(\"\\n3. Реализация ChatGPT:\")\n","try:\n","    dom_eigval_c_A, _ = power_iteration_chatgpt(A)\n","    all_eigvals_c_A, _ = find_all_eigenvalues_vectors_numpy(A)\n","    all_eigvals_c_A_sorted = np.sort(np.abs(all_eigvals_c_A))[::-1] # Сортировка по модулю для сравнения\n","    print(f\"   Доминантное с.з. (степенной метод): {dom_eigval_c_A:.6f}\")\n","    print(f\"   Все с.з. (numpy.linalg.eig): {np.round(np.sort(all_eigvals_c_A)[::-1], 6)}\")\n","    print(f\"   Разница доминантных с.з.: {np.abs(dominant_eigenvalue - dom_eigval_c_A):.2e}\")\n","    print(f\"   Разница всех с.з. (норма): {np.linalg.norm(np.sort(eigenvalues_np) - np.sort(all_eigvals_c_A)):.2e}\")\n","except Exception as e:\n","    print(f\"   Ошибка при выполнении кода ChatGPT: {e}\")\n","\n","\n","# 4. DeepSeek\n","print(\"\\n4. Реализация DeepSeek:\")\n","try:\n","    dom_eigval_gc_A, _ = power_method_deepseek(A)\n","    all_eigvals_gc_A, _ = get_eigen_numpy_deepseek(A)\n","    all_eigvals_gc_A_sorted = np.sort(np.abs(all_eigvals_gc_A))[::-1] # Сортировка по модулю для сравнения\n","    print(f\"   Доминантное с.з. (степенной метод): {dom_eigval_gc_A:.6f}\")\n","    print(f\"   Все с.з. (numpy.linalg.eig): {np.round(np.sort(all_eigvals_gc_A)[::-1], 6)}\")\n","    print(f\"   Разница доминантных с.з.: {np.abs(dominant_eigenvalue - dom_eigval_gc_A):.2e}\")\n","    print(f\"   Разница всех с.з. (норма): {np.linalg.norm(np.sort(eigenvalues_np) - np.sort(all_eigvals_gc_A)):.2e}\")\n","except Exception as e:\n","    print(f\"   Ошибка при выполнении кода DeepSeek: {e}\")"]},{"cell_type":"markdown","id":"65965f46","metadata":{"id":"65965f46"},"source":["### 6.4. Анализ полученных результатов\n","\n","| Модель        | Комментарий                                                                                                                                                                                                                                                                                       |\n","| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n","| Gemini (Google) | Предоставил рабочие функции как для степенного метода, так и для использования `np.linalg.eig`. Код хорошо структурирован, включает комментарии и проверку результатов (A\\*v ≈ λ\\*v), что очень полезно. Реализация степенного метода включает критерий остановки по толерантности.          |\n","| ChatGPT (OpenAI) | Также предоставил корректные и рабочие функции. Код лаконичен и соответствует запросу. Степенной метод реализован с критерием остановки.                                                                                                                                               |\n","| DeepSeek      | Сгенерировал рабочий код для обоих методов. Включил проверку `np.allclose` для `np.linalg.eig`, что является хорошей практикой. Использовал другую тестовую матрицу, но функции универсальны. Изначально в коде была ошибка вызова функции `full_eigen_decomposition(A)`, которая не была определена в сниппете, пришлось заменить на `get_eigen_numpy_deepseek(A)`. |\n","\n","Все три модели успешно сгенерировали код для нахождения собственных значений и векторов. Небольшие отличия заключаются в стиле кода, комментариях и способах проверки. Реализации степенного метода немного различаются (например, в способе оценки собственного значения и проверке сходимости), но все они следуют основной идее алгоритма. Код от DeepSeek потребовал минимального исправления из-за ошибки в вызове функции.\n"]},{"cell_type":"markdown","id":"60c4e1c5","metadata":{"id":"60c4e1c5"},"source":["---"]},{"cell_type":"markdown","id":"8a9de463","metadata":{"id":"8a9de463"},"source":["## Раздел 7. Оптимизация LLM при помощи метода главных компонент"]},{"cell_type":"markdown","id":"c9f1846a","metadata":{"id":"c9f1846a"},"source":["### Справка: Метод главных компонент простыми словами с акцентом на собственные числа и собственные векторы\n","\n","**Определение**\n","\n","Метод главных компонентов (PCA - Principal Component Analysis) это подход к уменьшению размерности, такой что:\n","1. Находит новые оси (основные компоненты), где данные отличаются больше всего.\n","2. Проецирует данные на меньшее количество измерений, сохраняя при этом максимальную дисперсию.\n","\n","**Как это работает с позиции собсвенных чисел и векторов:**\n","1. Берем матрицу данных `X` (например, включения токенов или скрытые слои LLM).\n","2. Вычисляем ковариационную матрицу:  \n","   $$\n","   C = \\frac{1}{n} X^T X\n","   $$\n","3. Находим собственные числа и собственные векторы ковариационной матрицы`C`.\n","   - *Собственные векторы* = направления (главные компоненты)\n","   - *Собственные числа* = величина отклонения (дисперсии), зафиксированная в каждом направлении\n","4. Выберем только *топ-k собственных векторов* (наибольшие собственные числа) → получим сокращённое число измерений.\n","\n","**Значение метода главных компонент для оптимизации размера LLM**\n","\n","1. Сжатия слоев встраивания (embedding kayers) или скрытых представлений\n","- Пример: Вы сокращаете 768-мерные встраивания BERT до 128D, используя 128 лучших собственных векторов → огромная экономия памяти.\n","- Полезно для **дистилляции**, **квантования** или **работе на устройстве**.\n","\n","2. Удалить избыточность в пространствах внимания (attention matrix)/фичах (Feature spaces)\n","- Заголовки внимания часто имеют \"низкоуровневую структуру\" (например, всего несколько доминирующих собственных мод).\n","- PCA может выявлять и \"сокращать\" или объединять заголовки, которые обладают сходными характеристиками.\n","\n","3. Проанализировать репрезентативную способность\n","Построение собственного значения **спектра** скрытых состояний говорит вам:\n","- Насколько выразительная часть модели сосредоточена всего в нескольких направлениях.\n","- Является ли результат работы слоя **низкоуровневым** (сжимаемым).\n","\n","\n","### Визуальное представление\n","- **Плоская кривая собственных значений** → разнообразные, высокоуровневые представления (сложнее сжимать).\n","- **Крутой спад собственных значений** → большая часть информации сосредоточена в нескольких направлениях (легко сжимается с помощью PCA).\n","\n","### Реальное приложение:\n","Google, Meta и HuggingFace использовали PCA и **низкоуровневую аппроксимацию** (например, усеченный SVD, линейные узкие места) для:\n","  - Сжатия моделей для мобильного развертывания.\n","  - Ускорения вывода.\n","  - Понять, на что модель \"обращает внимание\".\n","\n","\n","\n","**PCA использует собственные значения/векторы ковариационной матрицы для определения доминирующих направлений в данных. В LLMs PCA выявляет избыточную структуру и обеспечивает сжатие путем проецирования вложений/выходных данных в подпространство меньшей размерности, что делает модели более быстрыми и компактными без существенной потери точности.**"]},{"cell_type":"markdown","id":"c8658d43","metadata":{"id":"c8658d43"},"source":["7.1. Протокол запросов к выбранному (одному) ассистенту. Вы должны убедить его предоставить вам код оптимизации модели LLM (с которой Вы начинали работать в разделах 3-4), использующий метод главных компонентов с акцентом на использование методов расчёта собственных значений и собсвенных векторов. Также необходимо протестировать точность до и после оптимизации при помощи сокращённого набора данных (например, Tiny BERTScore (50 примеров)). Для оптимизации слой можно использовать любой, какой выберете или какой насоветует AI. Не обязательно сокращать все слои.\n","\n","7.2. Полученный в результате код (обновляете в процессе работы над этим разделом, можно оставить только то, что получится в итоге)\n","\n","7.3. Анализ трудностей и галлюцинаций на этом этапе. Как вы с этим справлялись (выявляли и исправляли).\n","\n","7.4. Анализ полученной оптимизированной модели и применения метода"]},{"cell_type":"markdown","id":"4f2afffc","metadata":{"id":"4f2afffc"},"source":["### 7.1. Протокол запросов к выбранному ассистенту.\n","\n","Укажите, какой выбрали в итоге AI-ассистент. Приведите список промптов, которые вы пробовали.\n","\n","Выбранный ассистент: **Gemini (Google)**\n","\n","Промпт 1:\n","\n","Я хочу уменьшить размерность матрицы весов одного из слоев LLM с помощью метода главных компонент (PCA). Мне нужно сохранить, скажем, 95% дисперсии. Покажи, как это сделать на Python, используя NumPy или Scikit-learn. Нужно:\n","1. Взять матрицу весов (предположим, она в переменной 'target_matrix').\n","2. Выполнить PCA (или использовать SVD, что тесно связано с PCA для ковариационной матрицы).\n","3. Определить количество компонент, необходимое для сохранения 95% дисперсии.\n","4. Получить матрицу проекции (компоненты PCA).\n","5. Опционально: показать, как можно было бы спроецировать исходную матрицу на пространство меньшей размерности и восстановить ее (с потерей информации)."]},{"cell_type":"markdown","id":"8d20106e","metadata":{"id":"8d20106e"},"source":["### 7.2. Полученный код (в результате совместной работы и доработок):"]},{"cell_type":"code","execution_count":33,"id":"e5b2f9e8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5b2f9e8","executionInfo":{"status":"ok","timestamp":1745945361019,"user_tz":-180,"elapsed":507,"user":{"displayName":"Роман Тимошкин","userId":"08933816501814017249"}},"outputId":"29bf2f6a-86b0-4a46-cba1-1fa05f670e95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Исходная размерность матрицы: (768, 768)\n","\n","--- Результаты PCA ---\n","Необходимое количество компонент для сохранения 95.0% дисперсии: 388\n","Фактически сохраненная доля дисперсии: 0.9503 (95.03%)\n","Доля дисперсии, объясняемая каждой компонентой: [0.01286784 0.01128501 0.01069112 0.00932693 0.00797869 0.00786707\n"," 0.00778011 0.00745845 0.00741655 0.00734801 0.00727699 0.00716053\n"," 0.0071362  0.00698394 0.00694198 0.00682403 0.00673526 0.00672915\n"," 0.00662187 0.00655235 0.00650778 0.00646553 0.00643839 0.00631162\n"," 0.00628755 0.00622782 0.00619011 0.0061369  0.00606686 0.00597847\n"," 0.00590639 0.00581772 0.0057987  0.00574746 0.00567227 0.00564209\n"," 0.00559153 0.00553519 0.00552118 0.00538841 0.00535818 0.0052699\n"," 0.00523871 0.00517568 0.00511436 0.00509587 0.00500868 0.00495467\n"," 0.00493427 0.00485945 0.00483432 0.00475583 0.00468894 0.00462882\n"," 0.00460698 0.00454504 0.00453372 0.00448768 0.0044521  0.00443664\n"," 0.00437881 0.00429182 0.00424983 0.00419139 0.00412667 0.00408764\n"," 0.00404979 0.00404748 0.00399289 0.00396188 0.00391911 0.00387707\n"," 0.00382025 0.00381469 0.00378331 0.00375993 0.00375798 0.00373133\n"," 0.00371795 0.00367874 0.00360697 0.00358731 0.00356501 0.00354354\n"," 0.00350598 0.00349065 0.00344979 0.00340311 0.00336526 0.00335784\n"," 0.00334826 0.00332202 0.00331708 0.00330355 0.0032801  0.00324599\n"," 0.00322484 0.00321264 0.00317474 0.00316249 0.00315434 0.00313667\n"," 0.00312123 0.00308415 0.00306811 0.00305133 0.00301812 0.00301432\n"," 0.00298217 0.00297154 0.00296477 0.00294708 0.00292827 0.00291078\n"," 0.00287013 0.0028686  0.0028663  0.00282344 0.00280762 0.00279939\n"," 0.00277013 0.00276449 0.00274352 0.00272923 0.00270615 0.00269674\n"," 0.00268175 0.0026607  0.00264585 0.00264021 0.00262253 0.00261003\n"," 0.00256891 0.00256638 0.00254534 0.00254198 0.00253714 0.00250517\n"," 0.0024924  0.00246865 0.00246171 0.00244769 0.0024306  0.00241674\n"," 0.00240196 0.0023906  0.00237447 0.00234174 0.00233743 0.00233227\n"," 0.00231551 0.00230155 0.0022836  0.00227407 0.00226695 0.00223223\n"," 0.00223047 0.00221097 0.00220865 0.00219917 0.00218108 0.00216879\n"," 0.00215116 0.00214397 0.00213675 0.00212309 0.0021027  0.00209703\n"," 0.00208416 0.00207701 0.00207011 0.00205963 0.00204444 0.00202821\n"," 0.00202092 0.0020153  0.00199455 0.00198652 0.00197057 0.00195651\n"," 0.00195325 0.00193935 0.00192499 0.00191387 0.00191067 0.0019015\n"," 0.00189014 0.00187789 0.00185806 0.00185518 0.00184099 0.00183063\n"," 0.00182532 0.00181576 0.00180676 0.00179506 0.00179299 0.00177445\n"," 0.00176289 0.00174369 0.00173191 0.00172404 0.00170572 0.00169816\n"," 0.00169543 0.00168868 0.00168302 0.00167285 0.00166376 0.00165729\n"," 0.00164423 0.0016309  0.00161727 0.00161002 0.0015901  0.0015818\n"," 0.00157772 0.00157058 0.00156292 0.00154658 0.00153927 0.00152728\n"," 0.00152603 0.00151495 0.0015144  0.00149053 0.00148019 0.00146859\n"," 0.00145822 0.00145269 0.00144634 0.00144335 0.00143835 0.0014319\n"," 0.00141506 0.00140211 0.00139503 0.00138869 0.00138557 0.00137079\n"," 0.00136764 0.00135697 0.00134808 0.00133869 0.00132857 0.00132584\n"," 0.0013092  0.00130706 0.00129945 0.00129449 0.00128489 0.00127882\n"," 0.00127273 0.00126741 0.00125303 0.00124861 0.00124602 0.00123127\n"," 0.00122312 0.00121305 0.00121062 0.00119901 0.00118949 0.0011835\n"," 0.00117987 0.00117084 0.00116335 0.00115759 0.00115086 0.00114064\n"," 0.00112752 0.00111574 0.00111344 0.00110774 0.00110111 0.00109885\n"," 0.00108551 0.00107269 0.00107064 0.00106729 0.00106002 0.00105471\n"," 0.00105185 0.00104837 0.00103908 0.00102707 0.00102538 0.00102068\n"," 0.00100639 0.00100475 0.00099994 0.0009913  0.0009824  0.00097471\n"," 0.00097053 0.00096677 0.00094921 0.00094631 0.0009368  0.00093204\n"," 0.00092748 0.00092075 0.00091565 0.00091207 0.00090547 0.00089435\n"," 0.00088787 0.0008836  0.00087873 0.00087013 0.00086769 0.00086031\n"," 0.00085525 0.00084687 0.00084389 0.00084141 0.00083263 0.00082519\n"," 0.00081705 0.00081481 0.00081234 0.00080043 0.00079951 0.00079269\n"," 0.00078964 0.00078164 0.00077696 0.00077299 0.00076944 0.00075871\n"," 0.00075359 0.00074901 0.00074777 0.00073732 0.00072999 0.00072794\n"," 0.00072639 0.0007227  0.00071169 0.00070725 0.00070183 0.00069924\n"," 0.00069294 0.00069063 0.00068377 0.00067757 0.00067124 0.00067069\n"," 0.00066933 0.00066081 0.00065171 0.00065056 0.00064727 0.00064313\n"," 0.00063188 0.00062908 0.00062753 0.00062451 0.00061794 0.00061027\n"," 0.00060939 0.00060687 0.00060253 0.00059771 0.0005927  0.00058917\n"," 0.00058528 0.00058169 0.00057819 0.00057128 0.00056705 0.00056399\n"," 0.00055617 0.00055402 0.00055197 0.00054387 0.00053809 0.0005317\n"," 0.00052963 0.00052337 0.00051956 0.00051471 0.00051181 0.00050965\n"," 0.00050738 0.00050207 0.00049622 0.00049184]\n","\n","Размерность матрицы проекции (главные компоненты): (388, 768)\n","\n","--- Проекция и Восстановление ---\n","Размерность спроецированной матрицы: (768, 388)\n","Размерность восстановленной матрицы: (768, 768)\n","Норма Фробениуса исходной матрицы: 186.3100\n","Норма Фробениуса ошибки восстановления: 41.4976\n","Относительная ошибка восстановления: 0.2227 (22.27%)\n"]}],"source":["import numpy as np\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt # Для опциональной визуализации\n","\n","# --- Шаг 1: Загрузка или создание матрицы весов ---\n","# Предположим, у нас есть матрица весов 'target_matrix'.\n","\n","print(f\"Исходная размерность матрицы: {target_matrix.shape}\")\n","\n","# --- Шаг 2: Выполнение PCA ---\n","# Мы хотим сохранить 95% дисперсии.\n","# Scikit-learn PCA позволяет указать долю дисперсии как n_components (от 0.0 до 1.0).\n","# PCA в scikit-learn по умолчанию центрирует данные (вычитает среднее).\n","# Это важно для корректной работы PCA.\n","variance_to_keep = 0.95\n","pca = PCA(n_components=variance_to_keep)\n","\n","# Обучаем PCA на нашей матрице.\n","# В контексте PCA, каждая строка матрицы рассматривается как отдельный \"образец\",\n","# а столбцы - как \"признаки\".\n","pca.fit(target_matrix)\n","\n","# --- Шаг 3: Определение количества компонент ---\n","# После обучения pca.n_components_ будет содержать количество компонент,\n","# необходимое для сохранения >= 95% дисперсии.\n","n_components_selected = pca.n_components_\n","explained_variance_ratio = pca.explained_variance_ratio_\n","total_explained_variance = np.sum(explained_variance_ratio)\n","\n","print(f\"\\n--- Результаты PCA ---\")\n","print(f\"Необходимое количество компонент для сохранения {variance_to_keep*100:.1f}% дисперсии: {n_components_selected}\")\n","print(f\"Фактически сохраненная доля дисперсии: {total_explained_variance:.4f} ({total_explained_variance*100:.2f}%)\")\n","print(f\"Доля дисперсии, объясняемая каждой компонентой: {explained_variance_ratio}\")\n","\n","# Можно посмотреть на кумулятивную сумму дисперсии\n","# cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n","# plt.figure(figsize=(8, 5))\n","# plt.plot(range(1, n_components_selected + 1), cumulative_variance_ratio, marker='.')\n","# plt.xlabel('Количество компонент')\n","# plt.ylabel('Кумулятивная доля объясненной дисперсии')\n","# plt.title('Зависимость объясненной дисперсии от количества компонент')\n","# plt.grid(True)\n","# plt.axhline(y=variance_to_keep, color='r', linestyle='--', label=f'{variance_to_keep*100:.0f}% порог')\n","# plt.legend()\n","# plt.show()\n","\n","\n","# --- Шаг 4: Получение матрицы проекции ---\n","# Главные компоненты (оси нового пространства) хранятся в pca.components_.\n","# Это и есть матрица проекции. Она имеет размерность (n_components, n_features),\n","# где n_features - исходное количество столбцов (768 в нашем примере).\n","# Каждая строка этой матрицы - это одна главная компонента (собственный вектор ковариационной матрицы).\n","projection_matrix = pca.components_\n","print(f\"\\nРазмерность матрицы проекции (главные компоненты): {projection_matrix.shape}\")\n","# Эта матрица используется для преобразования данных из исходного пространства\n","# (768 измерений) в пространство меньшей размерности (n_components_selected измерений).\n","# Проекция: Z = X @ projection_matrix.T  (где X - центрированные данные)\n","# В Scikit-learn это делает метод transform().\n","\n","\n","# --- Шаг 5 (Опционально): Проекция и восстановление ---\n","\n","# 5а. Проецирование исходной матрицы на пространство меньшей размерности\n","# Метод transform() центрирует данные и умножает их на projection_matrix.T\n","projected_matrix = pca.transform(target_matrix)\n","print(f\"\\n--- Проекция и Восстановление ---\")\n","print(f\"Размерность спроецированной матрицы: {projected_matrix.shape}\") # Будет (128, n_components_selected)\n","\n","# 5б. Восстановление матрицы (с потерей информации)\n","# Метод inverse_transform() выполняет обратное преобразование:\n","# Восстановленное = Спроецированное @ projection_matrix + Среднее\n","reconstructed_matrix = pca.inverse_transform(projected_matrix)\n","print(f\"Размерность восстановленной матрицы: {reconstructed_matrix.shape}\") # Вернется к (128, 768)\n","\n","# Оценка ошибки восстановления\n","reconstruction_error = np.linalg.norm(target_matrix - reconstructed_matrix, 'fro')\n","original_norm = np.linalg.norm(target_matrix, 'fro')\n","relative_error = reconstruction_error / original_norm\n","print(f\"Норма Фробениуса исходной матрицы: {original_norm:.4f}\")\n","print(f\"Норма Фробениуса ошибки восстановления: {reconstruction_error:.4f}\")\n","print(f\"Относительная ошибка восстановления: {relative_error:.4f} ({relative_error*100:.2f}%)\")\n","\n","# Важное замечание о связи с SVD:\n","# PCA тесно связан с сингулярным разложением (SVD). Если вы выполните SVD\n","# центрированной матрицы X_centered = U * S * Vt, то строки матрицы Vt\n","# (т.е. V.T) будут главными компонентами (собственными векторами X_centered.T @ X_centered),\n","# а квадраты сингулярных чисел S, поделенные на (количество_образцов - 1),\n","# дадут объясненную дисперсию (собственные значения ковариационной матрицы).\n","# Scikit-learn PCA часто использует SVD \"под капотом\" для вычислений, особенно для больших матриц."]},{"cell_type":"markdown","id":"b1a97514","metadata":{"id":"b1a97514"},"source":["### 7.3. Анализ трудностей и галлюцинаций на этом этапе. Как вы с этим справлялись (выявляли и исправляли).\n","\n","При работе с Gemini над задачей применения PCA к матрице весов LLM основные трудности были связаны не столько с галлюцинациями в коде (код для PCA с использованием `sklearn` был в целом корректен), сколько с необходимостью точно сформулировать запрос и интерпретировать результат в контексте LLM.\n","\n","В целом, галлюцинации на этом этапе были минимальны, но потребовалось внимательное чтение кода и осмысление результатов PCA в специфическом контексте весовых матриц LLM."]},{"cell_type":"markdown","id":"0f69f14f","metadata":{"id":"0f69f14f"},"source":["### 7.4. Анализ полученной оптимизированной модели и применения метода\n","\n","Применение метода главных компонент (PCA) к матрице весов `q_weights` размером `(768, 768)` для сохранения 95% дисперсии позволило сократить размерность до 388 компонент. Это показывает, что значительная часть вариативности исходного 768-мерного пространства может быть представлена в меньшем, 388-мерном подпространстве. Тот факт, что для 95% дисперсии потребовалась примерно половина исходных измерений, указывает на наличие избыточности в данных, при этом информация распределена по многим компонентам, а не сконцентрирована в нескольких доминирующих. Однако такое сжатие сопряжено с относительной ошибкой восстановления около 22.27%, что означает заметную потерю информации при реконструкции матрицы из главных компонент. Хотя результаты PCA, такие как матрица проекции и спроецированные данные, потенциально могут быть использованы для замены исходного линейного слоя в LLM на два меньших слоя для сокращения параметров, необходимо тщательно валидировать производительность измененной модели из-за существенной ошибки восстановления, которая может негативно повлиять на качество предсказаний. В целом, PCA выявил возможность сжатия матрицы весов, но его практическое применение требует оценки влияния на конечную производительность модели."]},{"cell_type":"markdown","id":"45712c46","metadata":{"id":"45712c46"},"source":["---"]},{"cell_type":"markdown","id":"f734eb5d","metadata":{"id":"f734eb5d"},"source":["Что хочется добавить к сегодняшнему занятию:\n","\n","1. [Код](https://github.com/tongjingqi/MathTrap) со ссылкой на статью про математические ловушки для LLM\n","\n","2. [Заметка](https://habr.com/ru/articles/904754/) о том, какие навыки *кажется следует* подтягивать программистам в современной индустрии\n","\n","3. Работая с различными AI-ассистентами, по крайней мере в Университете, будьте готовы к тому, что Вы не сможете получить максимум баллов за выполненные с их помощью работы, если только в задании не требуется обратное. Я провела опрос среди преподавателей нашего факультета (участие приняли 30 человек). 50% преподавателей высказались о том, что не поставят максимальный балл за работу выполненную с помощью GPT и аналогов, предлагая урезать баллы минимум в половину. Ещё 30% процентов поставят 0 баллов за такую работу и только лишь 20% преподавателей согласны принять работу выполненную при помощи ИИ-агентов и оценивать как выполненную самостоятельно."]},{"cell_type":"markdown","id":"02a847da","metadata":{"id":"02a847da"},"source":["## Итог\n","\n","Расскажите о Вашем сегодняшнем опыте: если это привычный способ изучения новой области, прототипирования, то на сколько удалось погрузиться в тему собственных чисел и оптимизации LLM. Если вообще все Вам показалось новым, включая общение с LLM, то расскажите, как Вы справлись с написанием промптов и кода? Если писали пропты на языке отличном от родного, то на сколько трудно это Вам показалось и какие подходы использовали (например, машинный перевод?)\n","\n","Как Вы сами оцениваете свой прогресс на сегодняшнем занятии?\n","\n","Удалось ли Вам изучить всё то, что перечисленно в самом первом списке в ноутбуке? Что вызвало наибольшее затруднение?\n","\n","---\n","\n","Опыт изучения собственных чисел, векторов и PCA для оптимизации моделей с помощью LLM (Gemini, ChatGPT, DeepSeek) был успешным.\n","\n","AI-ассистенты помогли быстро освоить основные концепции и получить готовый код на Python. Ключом было написание точных запросов с указанием всех деталей (библиотеки, методы).\n","\n","Сгенерированный код в основном работал, но иногда требовал небольших исправлений. Ошибки находились при запуске и проверке.\n","\n","Самой большой сложностью было не написание кода, а понимание результатов (например, почему PCA давал такие результаты на весах моделей) и исправление мелких ошибок AI.\n","\n","В целом, AI значительно ускорил процесс обучения и экспериментов, но требует критической проверки результатов и понимания предметной области. Это хороший инструмент для быстрого старта, но не замена глубоким знаниям."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.9"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"27d64ac3b8ee4e80b549a4deb99887d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6e3f45b78654bc1bf62dbc0035d05ac","IPY_MODEL_0077fae5754d46509fbffe026853bddc","IPY_MODEL_2d280c09d97d455fb348b0955d303544"],"layout":"IPY_MODEL_beb348fc241440f6af2d0ec984fb89a2"}},"f6e3f45b78654bc1bf62dbc0035d05ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a3397edba7d4d8d81e85fe29e028b7b","placeholder":"​","style":"IPY_MODEL_8ca7d848dc43468a8a1d269fce7b8882","value":"config.json: 100%"}},"0077fae5754d46509fbffe026853bddc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a03a90ef3fef4b03b151636b6f2f5bb3","max":762,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34331f3e9fb046d58d4c265bd97200dd","value":762}},"2d280c09d97d455fb348b0955d303544":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abe93a97682c47e18021022f4f8cbff3","placeholder":"​","style":"IPY_MODEL_42b3ecd95d7d4cdfbc9e6c963feb98b7","value":" 762/762 [00:00&lt;00:00, 44.6kB/s]"}},"beb348fc241440f6af2d0ec984fb89a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a3397edba7d4d8d81e85fe29e028b7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca7d848dc43468a8a1d269fce7b8882":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a03a90ef3fef4b03b151636b6f2f5bb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34331f3e9fb046d58d4c265bd97200dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abe93a97682c47e18021022f4f8cbff3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42b3ecd95d7d4cdfbc9e6c963feb98b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"328d2a20f36b48eebdbfb2e2cd78979d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ad78c76ecdf4709b7d7afd3a4cd8756","IPY_MODEL_79dd401853df4236beb13fb84bec2caf","IPY_MODEL_7210634865fc49459702f13cffa7ea4f"],"layout":"IPY_MODEL_8f16fc20eec346318aad57070aef55ba"}},"2ad78c76ecdf4709b7d7afd3a4cd8756":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3ad51e153ff4c37a0804582fe26e6d0","placeholder":"​","style":"IPY_MODEL_c11810f46e9146da9bef9646600fe804","value":"model.safetensors: 100%"}},"79dd401853df4236beb13fb84bec2caf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3bcfc78703e471e80e9d218096856c3","max":352824413,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d1413f4e9094d2bbc5e948ef2e0998e","value":352824413}},"7210634865fc49459702f13cffa7ea4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30968874167d4dcc903dea54cd1aac4e","placeholder":"​","style":"IPY_MODEL_7afffb7aebf241caa3d730eea52ef356","value":" 353M/353M [00:02&lt;00:00, 199MB/s]"}},"8f16fc20eec346318aad57070aef55ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3ad51e153ff4c37a0804582fe26e6d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c11810f46e9146da9bef9646600fe804":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3bcfc78703e471e80e9d218096856c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d1413f4e9094d2bbc5e948ef2e0998e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30968874167d4dcc903dea54cd1aac4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7afffb7aebf241caa3d730eea52ef356":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfcfb4832b3944d098c5742696217058":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7832bf573ec486ab62aad6a82857af1","IPY_MODEL_d6a92f3afae041c5968a26f764e21746","IPY_MODEL_aa51970403d34ccba957c393be286176"],"layout":"IPY_MODEL_c3671a2f1f30481f8757631e69d00ef4"}},"f7832bf573ec486ab62aad6a82857af1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d171878bcbb344f7a3cbd40f2d88b1d8","placeholder":"​","style":"IPY_MODEL_9f596ea855044fa99a287d6126aeb8c9","value":"generation_config.json: 100%"}},"d6a92f3afae041c5968a26f764e21746":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d400d3f68b8f44199d5d946e43803930","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02060c039b524fb086f2f243c268b04c","value":124}},"aa51970403d34ccba957c393be286176":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be344238a4564d45b1e0d24846842e43","placeholder":"​","style":"IPY_MODEL_d7689b4d2dfc46d4aa462860e590580e","value":" 124/124 [00:00&lt;00:00, 9.93kB/s]"}},"c3671a2f1f30481f8757631e69d00ef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d171878bcbb344f7a3cbd40f2d88b1d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f596ea855044fa99a287d6126aeb8c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d400d3f68b8f44199d5d946e43803930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02060c039b524fb086f2f243c268b04c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be344238a4564d45b1e0d24846842e43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7689b4d2dfc46d4aa462860e590580e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b7b91975e44463dbd7a0d6a32830d40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec89c79e89764efbbff65684f74e5fdb","IPY_MODEL_ac2808e829b44ffba0156d216862a65e","IPY_MODEL_da585288b935446f928d3d895d0b577d"],"layout":"IPY_MODEL_f51fb06d3acc4d2faa7c2acd152e8e95"}},"ec89c79e89764efbbff65684f74e5fdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ed251d72ac64ce690de474e801401e6","placeholder":"​","style":"IPY_MODEL_4a3441162ee7440ba90c2832799e5b44","value":"tokenizer_config.json: 100%"}},"ac2808e829b44ffba0156d216862a65e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d3a6034af994907aa6be34385740979","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e590229574c41b1ba5d9521e51b9212","value":26}},"da585288b935446f928d3d895d0b577d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94a973bda0ba4256bd64930f7dd061f7","placeholder":"​","style":"IPY_MODEL_de6d5207618447dbb936955c49d78bfa","value":" 26.0/26.0 [00:00&lt;00:00, 1.71kB/s]"}},"f51fb06d3acc4d2faa7c2acd152e8e95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ed251d72ac64ce690de474e801401e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a3441162ee7440ba90c2832799e5b44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d3a6034af994907aa6be34385740979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e590229574c41b1ba5d9521e51b9212":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94a973bda0ba4256bd64930f7dd061f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de6d5207618447dbb936955c49d78bfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dba8f83a60894bb3902a852917bfe963":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e18d88b1579438ba0d71ac93970590d","IPY_MODEL_c6cbb9a2ff36456a944c5da47b84aee5","IPY_MODEL_6c6f5e49387f471880d56212e919f888"],"layout":"IPY_MODEL_71f38f9d93da445fb7ee6480149a4fcc"}},"2e18d88b1579438ba0d71ac93970590d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3e38a7239474591b342edbc478f4b97","placeholder":"​","style":"IPY_MODEL_b36bee95cc2e4cbf8cd47b6e53268ca5","value":"vocab.json: 100%"}},"c6cbb9a2ff36456a944c5da47b84aee5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c0405a16a944e659e2b9a75f5a3114d","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3fa3e052177438fbb36744f7aab18d8","value":1042301}},"6c6f5e49387f471880d56212e919f888":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b34198d3831d4d6fb32e5523bb384dd3","placeholder":"​","style":"IPY_MODEL_05d8dcf08efa4e279d74fdee8e7374b2","value":" 1.04M/1.04M [00:00&lt;00:00, 6.29MB/s]"}},"71f38f9d93da445fb7ee6480149a4fcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3e38a7239474591b342edbc478f4b97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b36bee95cc2e4cbf8cd47b6e53268ca5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c0405a16a944e659e2b9a75f5a3114d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3fa3e052177438fbb36744f7aab18d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b34198d3831d4d6fb32e5523bb384dd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05d8dcf08efa4e279d74fdee8e7374b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df086bd1e0a24dfca0ac816115239e10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23a64687f20c433383658c19c2c7ae2c","IPY_MODEL_4f435f0ebd2a46718eb438182c4c7b57","IPY_MODEL_79bcecda94214b6fa7f61a864c4e9156"],"layout":"IPY_MODEL_93685806e0444a80a309864334d27f7b"}},"23a64687f20c433383658c19c2c7ae2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9468471674c471cb6ab866078260f21","placeholder":"​","style":"IPY_MODEL_0817b5c995ee457bbc011a859aeab17b","value":"merges.txt: 100%"}},"4f435f0ebd2a46718eb438182c4c7b57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f44a6501b1984b27ba088fdd846a632e","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37753a1da816493fb359c85780b31ac6","value":456318}},"79bcecda94214b6fa7f61a864c4e9156":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdb0414200904f5487c2760d91a397f9","placeholder":"​","style":"IPY_MODEL_290506aee2b44ab393726a42991aee9e","value":" 456k/456k [00:00&lt;00:00, 9.20MB/s]"}},"93685806e0444a80a309864334d27f7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9468471674c471cb6ab866078260f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0817b5c995ee457bbc011a859aeab17b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f44a6501b1984b27ba088fdd846a632e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37753a1da816493fb359c85780b31ac6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdb0414200904f5487c2760d91a397f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"290506aee2b44ab393726a42991aee9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9280c090c134fc09bd0554909c025ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bc4890e72b64f8babe2f990aa7e87d7","IPY_MODEL_c29c3c9fc4844d29bd1ceff0553e02ba","IPY_MODEL_847e5c4654114370842f8f33b9904b96"],"layout":"IPY_MODEL_a8f15cae368c4d058aa46b19ed5baa1c"}},"3bc4890e72b64f8babe2f990aa7e87d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6d42b4db6914e4eb63ca076da2bc931","placeholder":"​","style":"IPY_MODEL_02903f8e0c9e4e5e9e187991c0c246df","value":"tokenizer.json: 100%"}},"c29c3c9fc4844d29bd1ceff0553e02ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82ba4df2d26842d1904cccdbb0a303ab","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aead40bd7263494fbd4f7588d2fc5879","value":1355256}},"847e5c4654114370842f8f33b9904b96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45c8b5de1b0f42ef82c4bdd8aee3ca89","placeholder":"​","style":"IPY_MODEL_a891868e141143289a3ee9a16da90d36","value":" 1.36M/1.36M [00:00&lt;00:00, 15.0MB/s]"}},"a8f15cae368c4d058aa46b19ed5baa1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6d42b4db6914e4eb63ca076da2bc931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02903f8e0c9e4e5e9e187991c0c246df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82ba4df2d26842d1904cccdbb0a303ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aead40bd7263494fbd4f7588d2fc5879":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45c8b5de1b0f42ef82c4bdd8aee3ca89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a891868e141143289a3ee9a16da90d36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}